{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 457,
      "metadata": {
        "id": "vnTExAADftvB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxXym19bhG7A"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 458,
      "metadata": {
        "id": "KiMXAWmtprGN"
      },
      "outputs": [],
      "source": [
        "# Step 0 : filter on small caps and micro caps\n",
        "#def filter_data(df, small_cap_value=1, micro_cap_value=1):\n",
        "#    \"\"\"Filters rows based on small_cap and micro_cap values and returns a copy of the filtered DataFrame.\"\"\"\n",
        "#    filtered_df = df[(df['small_cap'] == small_cap_value) & (df['micro_cap'] == micro_cap_value)].copy()\n",
        "#    return filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 459,
      "metadata": {
        "id": "FKV_8oKrgACR"
      },
      "outputs": [],
      "source": [
        "# Step 1 : target creation + train_test_split\n",
        "# Creating target variables to automate creation of quarterly, yearly and 2-yearly targets, because well, DON'T REPEAT YOURSELF!\n",
        "def create_target_variable(df, frequency:int, threshold):\n",
        "    if frequency == 1:\n",
        "        col = 'mc_qtr_growth_pct'\n",
        "    if frequency == 4:\n",
        "        col = 'mc_yr_growth_pct'\n",
        "    if frequency == 8:\n",
        "        col = 'mc_2yr_growth_pct'\n",
        "   #else:\n",
        "   #    raise ValueError(\"Invalid frequency. Use 1 (quarterly), 4 (yearly), or 8 (2-year).\")\n",
        "    df[col] = df[col].shift(-frequency)\n",
        "    df.dropna(subset=col, inplace=True)\n",
        "    target_func = lambda x: 1 if ((x[col] > threshold) & (x.small_cap == 1)) else 0\n",
        "    df['target'] = df.apply(target_func, axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 460,
      "metadata": {
        "id": "-PdzMchGgMki"
      },
      "outputs": [],
      "source": [
        "#def drop_columns(df, cols_to_drop=None):\n",
        "#    \"\"\"Drops specified columns from the DataFrame.\"\"\"\n",
        "#\n",
        "#    if cols_to_drop is None:\n",
        "#       # Default columns to drop if none are specified\n",
        "#        cols_to_drop = ['cik', 'CIK', 'date', 'stprba', 'quarter', 'year']\n",
        "#    return df.drop(cols_to_drop, axis=1, errors='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 461,
      "metadata": {
        "id": "71DQCJUxgOaH"
      },
      "outputs": [],
      "source": [
        "# Creating a custom function for the group split\n",
        "def group_train_test_split(data, test_size=0.2, random_state=None):\n",
        "\n",
        "    data['qtr'] = data.quarter.apply(lambda x : x.split('-')[1])\n",
        "\n",
        "\n",
        "    # We split by groups (company ticker) while keeping the data structure intact.\n",
        "    unique_groups = data['TICKER'].unique()\n",
        "    train_groups, test_groups = train_test_split(unique_groups, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Split into train and test sets\n",
        "    X_train = data[data['TICKER'].isin(train_groups)]\n",
        "    X_test = data[data['TICKER'].isin(test_groups)]\n",
        "\n",
        "    # Define columns to drop: Ticker, cik, date, quarter, year + growth columns\n",
        "    cols_to_drop = ['mc_qtr_growth', 'mc_qtr_growth_pct', 'mc_yr_growth', 'mc_yr_growth_pct', 'mc_2yr_growth', 'mc_2yr_growth_pct', 'target']\n",
        "\n",
        "    # Drop unwanted columns\n",
        "    X_train = X_train.drop(cols_to_drop + ['cik', 'CIK', 'date', 'stprba', 'quarter', 'year', 'TICKER'], axis=1, errors='ignore')\n",
        "    X_test = X_test.drop(cols_to_drop + ['cik', 'CIK', 'date', 'stprba', 'quarter', 'year', 'TICKER'], axis=1, errors='ignore')\n",
        "\n",
        "    # Extract the target variable from the dataset\n",
        "    y_train = data[data['TICKER'].isin(train_groups)]['target']\n",
        "    y_test = data[data['TICKER'].isin(test_groups)]['target']\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 462,
      "metadata": {},
      "outputs": [],
      "source": [
        "## FULL SET (not test set)\n",
        "# # Creating a custom function to split data from target\n",
        "def group_train_split(data):\n",
        "\n",
        "    data['qtr'] = data.quarter.apply(lambda x : x.split('-')[1])\n",
        "\n",
        "    # No test set is created, we are keeping all groups in the training set.\n",
        "    train_groups = data['TICKER'].unique()\n",
        "\n",
        "    # Select all data as training set\n",
        "    X_train = data[data['TICKER'].isin(train_groups)]\n",
        "\n",
        "    # Define columns to drop: Ticker, cik, date, quarter, year + growth columns\n",
        "    cols_to_drop = ['mc_qtr_growth', 'mc_qtr_growth_pct', 'mc_yr_growth',\n",
        "                    'mc_yr_growth_pct', 'mc_2yr_growth', 'mc_2yr_growth_pct', 'target']\n",
        "\n",
        "    # Drop unwanted columns\n",
        "    X_train = X_train.drop(cols_to_drop + ['cik', 'CIK', 'date', 'stprba', 'quarter', 'year', 'TICKER'],\n",
        "                           axis=1, errors='ignore')\n",
        "\n",
        "    # Extract the target variable from the dataset\n",
        "    y_train = data[data['TICKER'].isin(train_groups)]['target']\n",
        "\n",
        "    return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 463,
      "metadata": {
        "id": "wvK02xu4gT3D"
      },
      "outputs": [],
      "source": [
        "# Step 2: Identify numerical and categorical features\n",
        "def identify_feature_types(df):\n",
        "    \"\"\"Identifies the numerical and categorical columns in the DataFrame.\"\"\"\n",
        "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    # Exclude 'Ticker' from categorical features as it's not needed for transformation\n",
        "    if 'TICKER' in categorical_features:\n",
        "        categorical_features.remove('TICKER')\n",
        "\n",
        "    return numerical_features, categorical_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 464,
      "metadata": {
        "id": "1TCupWcbgUoZ"
      },
      "outputs": [],
      "source": [
        "# Step 3: Create preprocessing pipeline for numerical and categorical features\n",
        "def create_preprocessing_pipeline(numerical_features, categorical_features):\n",
        "    \"\"\"Creates the preprocessing pipeline for numerical and categorical features.\"\"\"\n",
        "    # Preprocessing for numerical data: RobustScaler to make our numbers m√°s robusto.\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),  # Handle NaNs\n",
        "        ('scaler', RobustScaler())\n",
        "        #('scaler', MinMaxScaler()) # Scale the data\n",
        "    ])\n",
        "\n",
        "    # Preprocessing for categorical data: OneHotEncoder to give each category its own columm...\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing categories\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Encode categories\n",
        "    ])\n",
        "\n",
        "    # Combine the transformers into one big ColumnTransformer.\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "    return preprocessor\n",
        "\n",
        "\n",
        "# Function to save the preprocessor\n",
        "def save_preprocessor(preprocessor, file_path='~/models/'):\n",
        "    \"\"\"Saves the preproc with a timestamp.\"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    preproc_filename = f'preprocessor_{timestamp}.pkl'\n",
        "    # Ensure model directory exists\n",
        "    if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "    file_path = os.path.join(file_path, preproc_filename   )\n",
        "    with open(file_path, 'wb') as file:\n",
        "        pickle.dump(preprocessor, file)\n",
        "\n",
        "    print(f\"Preprocessor saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 465,
      "metadata": {
        "id": "o7c2Bq-wgX2j"
      },
      "outputs": [],
      "source": [
        "# Step 4: Function to preprocess data in training mode (fitting the pipeline)\n",
        "def preprocess_training_data(X_train):\n",
        "    \"\"\"Fits and transforms the training data using the provided pipeline.\"\"\"\n",
        "    # Identify feature types\n",
        "    numerical_features, categorical_features = identify_feature_types(X_train)\n",
        "    preprocessor = create_preprocessing_pipeline(numerical_features, categorical_features)\n",
        "\n",
        "    # Fit and transform the training data\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "        # Save the preprocessor after fitting\n",
        "    save_preprocessor(preprocessor)\n",
        "\n",
        "    return X_train_processed, preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 466,
      "metadata": {
        "id": "nKfwqkKtglqk"
      },
      "outputs": [],
      "source": [
        "# Step 5: Function to preprocess new/unseen/test data in production mode (only transforming)\n",
        "def preprocess_new_data(X_new, preprocessor):\n",
        "    \"\"\"Transforms new/unseen/test data using a pre-fitted pipeline.\"\"\"\n",
        "    if preprocessor is None:\n",
        "        raise ValueError(\"The preprocessor must be fitted on training data first before transforming new data.\")\n",
        "\n",
        "    # Transform the new data (no fitting here)\n",
        "    X_new_processed = preprocessor.transform(X_new)\n",
        "    return X_new_processed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43XuFL6dg6GU"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 467,
      "metadata": {
        "id": "_avhOzqdgtaj"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_type, model_dir='~/models/'):\n",
        "    \"\"\"Saves the trained model with a timestamp.\"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    model_filename = f'{model_type}_{timestamp}.pkl'\n",
        "\n",
        "    # Ensure model directory exists\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    # Save the trained model\n",
        "    model_path = os.path.join(model_dir, model_filename)\n",
        "    with open(model_path, 'wb') as f_model:\n",
        "        pickle.dump(model, f_model)\n",
        "\n",
        "    print(f\"Model saved to: {model_path}\")\n",
        "    return model_path\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test, scoring_metrics=['accuracy', 'precision', 'recall', 'f1']):\n",
        "    \"\"\"Evaluates the model with cross-validation and test set metrics.\"\"\"\n",
        "    cv_metrics = {}\n",
        "    for metric in scoring_metrics:\n",
        "        with tqdm(total=5, desc=f\"Cross-Validation ({metric})\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "            cv_metrics[metric] = cross_val_score(model, X_train, y_train, cv=5, scoring=metric)\n",
        "            pbar.update(5)\n",
        "\n",
        "    print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics[m].mean():.4f}' for m in cv_metrics])}\")\n",
        "\n",
        "    # Test on the test set\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Calculate test set metrics\n",
        "    test_metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred_test),\n",
        "        'precision': precision_score(y_test, y_pred_test),\n",
        "        'recall': recall_score(y_test, y_pred_test),\n",
        "        'f1': f1_score(y_test, y_pred_test)\n",
        "    }\n",
        "\n",
        "    # Combine cross-validated and test metrics\n",
        "    metrics = {**{f'cv_{m}': cv_metrics[m].mean() for m in cv_metrics}, **test_metrics}\n",
        "    return metrics\n",
        "\n",
        "def train_logistic_regression_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates a logistic regression model, saves the trained model, and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    model_type = 'logistic_regression'\n",
        "    model = LogisticRegression(C=0.001, max_iter=2000, solver='lbfgs')\n",
        "\n",
        "    # Train model with a progress bar\n",
        "    with tqdm(total=100, desc=f\"Training {model_type}\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "        model.fit(X_train, y_train)\n",
        "        pbar.update(100)\n",
        "\n",
        "    # Check number of iterations\n",
        "    print(f\"Number of iterations: {model.n_iter_}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(model, model_type, model_dir)\n",
        "\n",
        "    return metrics, model\n",
        "\n",
        "def train_knn_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates a K-Nearest Neighbors model, saves the trained model, and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    model_type = 'knn'\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Train model with a progress bar\n",
        "    with tqdm(total=100, desc=f\"Training {model_type}\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "        knn.fit(X_train, y_train)\n",
        "        pbar.update(100)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(knn, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(knn, model_type, model_dir)\n",
        "\n",
        "    return metrics, knn\n",
        "\n",
        "def train_svc_rbf_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates an SVM with RBF kernel, saves the trained model, and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    model_type = 'svc_rbf'\n",
        "    svc_rbf = SVC(kernel='rbf', probability=True)  # Set `probability=True` for log_loss and cross-validation\n",
        "\n",
        "    # Train model with a progress bar\n",
        "    #with tqdm(total=100, desc=f\"Training {model_type}\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "    svc_rbf.fit(X_train, y_train)\n",
        "        #pbar.update(100)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(svc_rbf, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(svc_rbf, model_type, model_dir)\n",
        "\n",
        "    return metrics, svc_rbf\n",
        "\n",
        "\n",
        "def train_xgb_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates an XGBClassifier model, saves the trained model, and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    model_type = 'xgb_classifier'\n",
        "\n",
        "    # Initialize XGBClassifier with specified parameters and verbose for progress monitoring\n",
        "    xgb = XGBClassifier(n_estimators=200, learning_rate=0.01, max_depth=5, verbose=1)\n",
        "\n",
        "    # Train the model\n",
        "    xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(xgb, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(xgb, model_type, model_dir)\n",
        "\n",
        "    return metrics, xgb\n",
        "\n",
        "def fullset_train_xgb_and_save(X_train, y_train, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates an XGBClassifier model, saves the trained model, and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    model_type = 'xgb_classifier'\n",
        "\n",
        "    # Initialize XGBClassifier with specified parameters and verbose for progress monitoring\n",
        "    xgb = XGBClassifier(n_estimators=200, learning_rate=0.01, max_depth=5, verbose=1)\n",
        "\n",
        "    # Train the model\n",
        "    #xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
        "    xgb.fit(X_train, y_train, verbose=True)\n",
        "\n",
        "    # Evaluate the model\n",
        "    # metrics = evaluate_model(xgb, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(xgb, model_type, model_dir)\n",
        "\n",
        "    return xgb  #metrics,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 468,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'# Step 6: Function to train logistic regression, evaluate, and save the model\\ndef train_logistic_regression_and_save(X_train, y_train, X_test, y_test, model_dir=\\'~/models/\\'):\\n    \"\"\"Trains, evaluates a logistic regression model, saves the trained model with a timestamp and returns evaluation metrics.\"\"\"\\n\\n    # Step 1: Train logistic regression model with a progress bar\\n    logistic_model = LogisticRegression(solver=\\'saga\\', max_iter=2000)\\n    with tqdm(total=100, desc=\"Training Logistic Regression\", bar_format=\\'{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]\\') as pbar:\\n        logistic_model.fit(X_train, y_train)\\n        pbar.update(100)\\n\\n    # Check number of iterations\\n    print(f\"Number of iterations: {logistic_model.n_iter_}\")\\n\\n    # Step 2: Evaluate using cross-validation for accuracy, precision, recall, and F1-score\\n    cv_metrics = {}\\n    for metric in [\\'accuracy\\', \\'precision\\', \\'recall\\', \\'f1\\']:\\n        with tqdm(total=5, desc=f\"Cross-Validation ({metric})\", bar_format=\\'{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]\\') as pbar:\\n            cv_metrics[metric] = cross_val_score(logistic_model, X_train, y_train, cv=5, scoring=metric)\\n            pbar.update(5)\\n\\n    print(f\"Cross-validated Metrics: {\\', \\'.join([f\\'{m}: {cv_metrics[m].mean():.4f}\\' for m in cv_metrics])}\")\\n\\n    # Step 3: Test on the test set\\n    y_pred_test = logistic_model.predict(X_test)\\n\\n    # Calculate test set metrics\\n    test_metrics = {\\n        \\'accuracy\\': accuracy_score(y_test, y_pred_test),\\n        \\'precision\\': precision_score(y_test, y_pred_test),\\n        \\'recall\\': recall_score(y_test, y_pred_test),\\n        \\'f1\\': f1_score(y_test, y_pred_test)\\n    }\\n\\n    # Combine cross-validated and test metrics into a single dictionary\\n    metrics = {**{f\\'cv_{m}\\': cv_metrics[m].mean() for m in cv_metrics}, **test_metrics}\\n\\n    # Step 4: Save the model with timestamp and type\\n    timestamp = datetime.now().strftime(\\'%Y-%m-%d_%H-%M-%S\\')\\n    model_filename = f\\'logistic_regression_{timestamp}.pkl\\'\\n\\n    # Ensure model directory exists\\n    if not os.path.exists(model_dir):\\n        os.makedirs(model_dir)\\n\\n    # Save the trained model\\n    model_path = os.path.join(model_dir, model_filename)\\n    with open(model_path, \\'wb\\') as f_model:\\n        pickle.dump(logistic_model, f_model)\\n\\n    print(f\"Model saved to: {model_path}\")\\n\\n    return metrics, logistic_model'"
            ]
          },
          "execution_count": 468,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''# Step 6: Function to train logistic regression, evaluate, and save the model\n",
        "def train_logistic_regression_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates a logistic regression model, saves the trained model with a timestamp and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    # Step 1: Train logistic regression model with a progress bar\n",
        "    logistic_model = LogisticRegression(solver='saga', max_iter=2000)\n",
        "    with tqdm(total=100, desc=\"Training Logistic Regression\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "        logistic_model.fit(X_train, y_train)\n",
        "        pbar.update(100)\n",
        "\n",
        "    # Check number of iterations\n",
        "    print(f\"Number of iterations: {logistic_model.n_iter_}\")\n",
        "\n",
        "    # Step 2: Evaluate using cross-validation for accuracy, precision, recall, and F1-score\n",
        "    cv_metrics = {}\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        with tqdm(total=5, desc=f\"Cross-Validation ({metric})\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "            cv_metrics[metric] = cross_val_score(logistic_model, X_train, y_train, cv=5, scoring=metric)\n",
        "            pbar.update(5)\n",
        "\n",
        "    print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics[m].mean():.4f}' for m in cv_metrics])}\")\n",
        "\n",
        "    # Step 3: Test on the test set\n",
        "    y_pred_test = logistic_model.predict(X_test)\n",
        "\n",
        "    # Calculate test set metrics\n",
        "    test_metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred_test),\n",
        "        'precision': precision_score(y_test, y_pred_test),\n",
        "        'recall': recall_score(y_test, y_pred_test),\n",
        "        'f1': f1_score(y_test, y_pred_test)\n",
        "    }\n",
        "\n",
        "    # Combine cross-validated and test metrics into a single dictionary\n",
        "    metrics = {**{f'cv_{m}': cv_metrics[m].mean() for m in cv_metrics}, **test_metrics}\n",
        "\n",
        "    # Step 4: Save the model with timestamp and type\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    model_filename = f'logistic_regression_{timestamp}.pkl'\n",
        "\n",
        "    # Ensure model directory exists\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    # Save the trained model\n",
        "    model_path = os.path.join(model_dir, model_filename)\n",
        "    with open(model_path, 'wb') as f_model:\n",
        "        pickle.dump(logistic_model, f_model)\n",
        "\n",
        "    print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "    return metrics, logistic_model'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 469,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_grid_search(X_train, y_train):\n",
        "    \"\"\"Runs a grid search on logistic regression model to find the best hyperparameters.\"\"\"\n",
        "\n",
        "    # Define the parameter grid for Logistic Regression\n",
        "    param_grid = {\n",
        "        'solver': ['saga', 'lbfgs'],  # Different solvers\n",
        "        'max_iter': [1500, 2000, 2500],  # Number of iterations\n",
        "        'C': [0.005, 0.007, 0.01, 0.12, 0.15]  # Regularization strength\n",
        "    }\n",
        "\n",
        "    # Create a Logistic Regression model\n",
        "    logistic_model = LogisticRegression()\n",
        "\n",
        "    # Set up the GridSearchCV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=logistic_model,\n",
        "        param_grid=param_grid,\n",
        "        scoring='precision',  # Choose appropriate scoring metric\n",
        "        cv=5,  # Number of cross-validation folds\n",
        "        n_jobs=-1,  # Use all available cores\n",
        "        verbose=1  # Verbosity level\n",
        "    )\n",
        "\n",
        "    # Fit Grid Search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "    print(f\"Best cross-validation score: {best_score:.4f}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    return best_model, best_params, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 470,
      "metadata": {},
      "outputs": [],
      "source": [
        "def knn_run_grid_search(X_train, y_train):\n",
        "    \"\"\"Runs a grid search on knn model to find the best hyperparameters.\"\"\"\n",
        "\n",
        "    # Define the parameter grid for Logistic Regression\n",
        "    param_grid = {\n",
        "        'n_neighbors': [550],  # Different solvers\n",
        "        #'max_iter': [1500, 2000, 2500],  # Number of iterations\n",
        "        #'C': [0.005, 0.007, 0.01, 0.12, 0.15]  # Regularization strength\n",
        "    }\n",
        "\n",
        "    # Create a Logistic Regression model\n",
        "    knn_model = KNeighborsClassifier()\n",
        "\n",
        "    # Set up the GridSearchCV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=knn_model,\n",
        "        param_grid=param_grid,\n",
        "        scoring='precision',  # Choose appropriate scoring metric\n",
        "        cv=3,  # Number of cross-validation folds\n",
        "        n_jobs=-1,  # Use all available cores\n",
        "        verbose=1  # Verbosity level\n",
        "    )\n",
        "\n",
        "    # Fit Grid Search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "    print(f\"Best cross-validation score: {best_score:.4f}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    return best_model, best_params, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 471,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_xgboost(X_train, y_train):\n",
        "    \"\"\"Runs a grid search on knn model to find the best hyperparameters.\"\"\"\n",
        "\n",
        "    # Define the parameter grid for Logistic Regression\n",
        "    param_grid = param_grid = {'n_estimators': [200],\n",
        "                               'learning_rate': [0.01],\n",
        "                               'max_depth': [5]}\n",
        "\n",
        "#{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
        "\n",
        "    # Create a Logistic Regression model\n",
        "    model = XGBClassifier()\n",
        "\n",
        "    # Set up the search\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grid,\n",
        "        scoring='precision',  # Choose appropriate scoring metric\n",
        "        cv=3,  # Number of cross-validation folds\n",
        "        n_jobs=-1,  # Use all available cores\n",
        "        verbose=1  # Verbosity level\n",
        "    )\n",
        "\n",
        "    # Fit Grid Search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "    print(f\"Best cross-validation score: {best_score:.4f}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    return best_model, best_params, best_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnR372rBhduh"
      },
      "source": [
        "# **Running the functions on the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 472,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_7Ktzy3hj9u",
        "outputId": "00c8bbe3-1775-467b-ba43-4039b75fd042"
      },
      "outputs": [],
      "source": [
        "\n",
        "# preprocessor import create_target_variable, group_train_test_split, identify_feature_types, create_preprocessing_pipeline,preprocess_training_data, preprocess_new_data,train_logistic_regression, filter_data\n",
        "\n",
        "\n",
        "df = pd.read_csv('~/Small-Cap-Scout/raw_data/data_for_preprocessing.csv', index_col=[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 473,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "hl1aO3mihsKZ",
        "outputId": "9d7e5310-9db6-4671-9172-4bd86b40c8f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cik</th>\n",
              "      <th>date</th>\n",
              "      <th>Assets</th>\n",
              "      <th>AssetsCurrent</th>\n",
              "      <th>Cash</th>\n",
              "      <th>AssetsNoncurrent</th>\n",
              "      <th>Liabilities</th>\n",
              "      <th>LiabilitiesCurrent</th>\n",
              "      <th>LiabilitiesNoncurrent</th>\n",
              "      <th>Equity</th>\n",
              "      <th>...</th>\n",
              "      <th>TICKER</th>\n",
              "      <th>market_cap</th>\n",
              "      <th>mc_qtr_growth</th>\n",
              "      <th>mc_qtr_growth_pct</th>\n",
              "      <th>mc_yr_growth</th>\n",
              "      <th>mc_yr_growth_pct</th>\n",
              "      <th>mc_2yr_growth</th>\n",
              "      <th>mc_2yr_growth_pct</th>\n",
              "      <th>small_cap</th>\n",
              "      <th>micro_cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011-02-28</td>\n",
              "      <td>1.655991e+09</td>\n",
              "      <td>9.278390e+08</td>\n",
              "      <td>54716000.0</td>\n",
              "      <td>409295000.0</td>\n",
              "      <td>8.513950e+08</td>\n",
              "      <td>419182000.0</td>\n",
              "      <td>432213000.0</td>\n",
              "      <td>804596000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>1045.889727</td>\n",
              "      <td>46.783392</td>\n",
              "      <td>0.046825</td>\n",
              "      <td>77.281557</td>\n",
              "      <td>0.079786</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011-05-31</td>\n",
              "      <td>1.703727e+09</td>\n",
              "      <td>9.139850e+08</td>\n",
              "      <td>57433000.0</td>\n",
              "      <td>465365000.0</td>\n",
              "      <td>8.684380e+08</td>\n",
              "      <td>416010000.0</td>\n",
              "      <td>452428000.0</td>\n",
              "      <td>835289000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>1024.472219</td>\n",
              "      <td>-21.417508</td>\n",
              "      <td>-0.020478</td>\n",
              "      <td>306.796787</td>\n",
              "      <td>0.427487</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011-08-31</td>\n",
              "      <td>1.752372e+09</td>\n",
              "      <td>9.442470e+08</td>\n",
              "      <td>35523000.0</td>\n",
              "      <td>472856000.0</td>\n",
              "      <td>9.032430e+08</td>\n",
              "      <td>350085000.0</td>\n",
              "      <td>553158000.0</td>\n",
              "      <td>849129000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>882.619592</td>\n",
              "      <td>-141.852627</td>\n",
              "      <td>-0.138464</td>\n",
              "      <td>255.395538</td>\n",
              "      <td>0.407184</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011-11-30</td>\n",
              "      <td>1.821612e+09</td>\n",
              "      <td>9.550530e+08</td>\n",
              "      <td>27870000.0</td>\n",
              "      <td>521431000.0</td>\n",
              "      <td>9.582200e+08</td>\n",
              "      <td>374944000.0</td>\n",
              "      <td>583276000.0</td>\n",
              "      <td>863392000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>727.886752</td>\n",
              "      <td>-154.732840</td>\n",
              "      <td>-0.175311</td>\n",
              "      <td>-271.219583</td>\n",
              "      <td>-0.271462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1750</td>\n",
              "      <td>2012-02-29</td>\n",
              "      <td>2.220293e+09</td>\n",
              "      <td>1.065389e+09</td>\n",
              "      <td>59294000.0</td>\n",
              "      <td>797765000.0</td>\n",
              "      <td>1.328974e+09</td>\n",
              "      <td>560986000.0</td>\n",
              "      <td>767988000.0</td>\n",
              "      <td>891319000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>899.522315</td>\n",
              "      <td>171.635564</td>\n",
              "      <td>0.235800</td>\n",
              "      <td>-146.367411</td>\n",
              "      <td>-0.139945</td>\n",
              "      <td>-69.085854</td>\n",
              "      <td>-0.071325</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 59 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    cik        date        Assets  AssetsCurrent        Cash  \\\n",
              "0  1750  2011-02-28  1.655991e+09   9.278390e+08  54716000.0   \n",
              "1  1750  2011-05-31  1.703727e+09   9.139850e+08  57433000.0   \n",
              "2  1750  2011-08-31  1.752372e+09   9.442470e+08  35523000.0   \n",
              "3  1750  2011-11-30  1.821612e+09   9.550530e+08  27870000.0   \n",
              "4  1750  2012-02-29  2.220293e+09   1.065389e+09  59294000.0   \n",
              "\n",
              "   AssetsNoncurrent   Liabilities  LiabilitiesCurrent  LiabilitiesNoncurrent  \\\n",
              "0       409295000.0  8.513950e+08         419182000.0            432213000.0   \n",
              "1       465365000.0  8.684380e+08         416010000.0            452428000.0   \n",
              "2       472856000.0  9.032430e+08         350085000.0            553158000.0   \n",
              "3       521431000.0  9.582200e+08         374944000.0            583276000.0   \n",
              "4       797765000.0  1.328974e+09         560986000.0            767988000.0   \n",
              "\n",
              "        Equity  ...  TICKER   market_cap  mc_qtr_growth  mc_qtr_growth_pct  \\\n",
              "0  804596000.0  ...     AIR  1045.889727      46.783392           0.046825   \n",
              "1  835289000.0  ...     AIR  1024.472219     -21.417508          -0.020478   \n",
              "2  849129000.0  ...     AIR   882.619592    -141.852627          -0.138464   \n",
              "3  863392000.0  ...     AIR   727.886752    -154.732840          -0.175311   \n",
              "4  891319000.0  ...     AIR   899.522315     171.635564           0.235800   \n",
              "\n",
              "   mc_yr_growth  mc_yr_growth_pct  mc_2yr_growth  mc_2yr_growth_pct  \\\n",
              "0     77.281557          0.079786            NaN                NaN   \n",
              "1    306.796787          0.427487            NaN                NaN   \n",
              "2    255.395538          0.407184            NaN                NaN   \n",
              "3   -271.219583         -0.271462            NaN                NaN   \n",
              "4   -146.367411         -0.139945     -69.085854          -0.071325   \n",
              "\n",
              "   small_cap  micro_cap  \n",
              "0          1          0  \n",
              "1          1          0  \n",
              "2          1          0  \n",
              "3          1          0  \n",
              "4          1          0  \n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "execution_count": 473,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 474,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ren7WhjaxXoH",
        "outputId": "4c2c7da9-4af8-4fe0-ee78-44d18e9f5224"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['cik', 'date', 'Assets', 'AssetsCurrent', 'Cash', 'AssetsNoncurrent',\n",
              "       'Liabilities', 'LiabilitiesCurrent', 'LiabilitiesNoncurrent', 'Equity',\n",
              "       'HolderEquity', 'RetainedEarnings', 'AdditionalPaidInCapital',\n",
              "       'TreasuryStockValue', 'TemporaryEquity', 'RedeemableEquity',\n",
              "       'LiabilitiesAndEquity', 'Revenues', 'CostOfRevenue', 'GrossProfit',\n",
              "       'OperatingExpenses', 'OperatingIncomeLoss',\n",
              "       'IncomeLossFromContinuingOperationsBeforeIncomeTaxExpenseBenefit',\n",
              "       'AllIncomeTaxExpenseBenefit', 'IncomeLossFromContinuingOperations',\n",
              "       'IncomeLossFromDiscontinuedOperationsNetOfTax', 'ProfitLoss',\n",
              "       'NetIncomeLossAttributableToNoncontrollingInterest', 'NetIncomeLoss',\n",
              "       'NetCashProvidedByUsedInOperatingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInFinancingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInInvestingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInOperatingActivities',\n",
              "       'NetCashProvidedByUsedInFinancingActivities',\n",
              "       'NetCashProvidedByUsedInInvestingActivities',\n",
              "       'CashProvidedByUsedInOperatingActivitiesDiscontinuedOperations',\n",
              "       'CashProvidedByUsedInInvestingActivitiesDiscontinuedOperations',\n",
              "       'CashProvidedByUsedInFinancingActivitiesDiscontinuedOperations',\n",
              "       'EffectOfExchangeRateFinal',\n",
              "       'CashPeriodIncreaseDecreaseIncludingExRateEffectFinal', 'afs', 'sic_2d',\n",
              "       'quarter', 'year', 'GDP', 'interest_rate', 'unemployment_rate',\n",
              "       'median_cpi', 'CIK', 'TICKER', 'market_cap', 'mc_qtr_growth',\n",
              "       'mc_qtr_growth_pct', 'mc_yr_growth', 'mc_yr_growth_pct',\n",
              "       'mc_2yr_growth', 'mc_2yr_growth_pct', 'small_cap', 'micro_cap'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 474,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 475,
      "metadata": {
        "id": "c1P5otIWl2Dl"
      },
      "outputs": [],
      "source": [
        "# Step 2: Drop unwanted columns before target creation\n",
        "#df_cleaned = drop_columns(df, cols_to_drop=['cik', 'CIK', 'date', 'stprba', 'quarter', 'year', ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 476,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_cleaned.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 477,
      "metadata": {
        "id": "fqikqbbIl-TV"
      },
      "outputs": [],
      "source": [
        "# Step 3: Create target variables and split the data\n",
        "df_qtr = create_target_variable(df, frequency=1, threshold=0.3)\n",
        "df_yr = create_target_variable(df, frequency=4, threshold=0.3)\n",
        "df_2yr = create_target_variable(df, frequency=8, threshold=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 478,
      "metadata": {
        "id": "s22arfsqmA2H"
      },
      "outputs": [],
      "source": [
        "#X_train_qtr, X_test_qtr, y_train_qtr, y_test_qtr = group_train_test_split(df_qtr)\n",
        "#X_train_yr, X_test_yr, y_train_yr, y_test_yr = group_train_test_split(df_yr)\n",
        "#X_train_2yr, X_test_2yr, y_train_2yr, y_test_2yr = group_train_test_split(df_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 479,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_qtr, y_train_qtr = group_train_split(df_qtr)\n",
        "X_train_yr, y_train_yr = group_train_split(df_yr)\n",
        "X_train_2yr, y_train_2yr = group_train_split(df_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 480,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Assets', 'AssetsCurrent', 'Cash', 'AssetsNoncurrent', 'Liabilities',\n",
              "       'LiabilitiesCurrent', 'LiabilitiesNoncurrent', 'Equity', 'HolderEquity',\n",
              "       'RetainedEarnings', 'AdditionalPaidInCapital', 'TreasuryStockValue',\n",
              "       'TemporaryEquity', 'RedeemableEquity', 'LiabilitiesAndEquity',\n",
              "       'Revenues', 'CostOfRevenue', 'GrossProfit', 'OperatingExpenses',\n",
              "       'OperatingIncomeLoss',\n",
              "       'IncomeLossFromContinuingOperationsBeforeIncomeTaxExpenseBenefit',\n",
              "       'AllIncomeTaxExpenseBenefit', 'IncomeLossFromContinuingOperations',\n",
              "       'IncomeLossFromDiscontinuedOperationsNetOfTax', 'ProfitLoss',\n",
              "       'NetIncomeLossAttributableToNoncontrollingInterest', 'NetIncomeLoss',\n",
              "       'NetCashProvidedByUsedInOperatingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInFinancingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInInvestingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInOperatingActivities',\n",
              "       'NetCashProvidedByUsedInFinancingActivities',\n",
              "       'NetCashProvidedByUsedInInvestingActivities',\n",
              "       'CashProvidedByUsedInOperatingActivitiesDiscontinuedOperations',\n",
              "       'CashProvidedByUsedInInvestingActivitiesDiscontinuedOperations',\n",
              "       'CashProvidedByUsedInFinancingActivitiesDiscontinuedOperations',\n",
              "       'EffectOfExchangeRateFinal',\n",
              "       'CashPeriodIncreaseDecreaseIncludingExRateEffectFinal', 'afs', 'sic_2d',\n",
              "       'GDP', 'interest_rate', 'unemployment_rate', 'median_cpi', 'market_cap',\n",
              "       'small_cap', 'micro_cap', 'qtr'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 480,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_qtr.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 481,
      "metadata": {
        "id": "VxzH3rREuc4t"
      },
      "outputs": [],
      "source": [
        "# Step 4:  Identify feature types after splitting\n",
        "#numerical_features_qtr, categorical_features_qtr = identify_feature_types(X_train_qtr)\n",
        "#numerical_features_yr, categorical_features_yr = identify_feature_types(X_train_yr)\n",
        "#numerical_features_2yr, categorical_features_2yr = identify_feature_types(X_train_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 482,
      "metadata": {
        "id": "abVrvnn6ztXY"
      },
      "outputs": [],
      "source": [
        "# Step 5: Create the preprocessing pipeline\n",
        "#preprocessor_qtr = create_preprocessing_pipeline(numerical_features_qtr, categorical_features_qtr)\n",
        "#preprocessor_yr = create_preprocessing_pipeline(numerical_features_yr, categorical_features_yr)\n",
        "#preprocessor_2yr = create_preprocessing_pipeline(numerical_features_2yr, categorical_features_2yr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 483,
      "metadata": {
        "id": "ChuCubny0QXz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessor saved to ~/models/preprocessor_2024-09-12_11-11-38.pkl\n",
            "Preprocessor saved to ~/models/preprocessor_2024-09-12_11-11-39.pkl\n",
            "Preprocessor saved to ~/models/preprocessor_2024-09-12_11-11-39.pkl\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Preprocess the training data\n",
        "X_train_qtr_processed, preprocessor_qtr = preprocess_training_data(X_train_qtr)\n",
        "X_train_yr_processed, preprocessor_yr = preprocess_training_data(X_train_yr)\n",
        "X_train_2yr_processed, preprocessor_2yr = preprocess_training_data(X_train_2yr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 484,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.313023</td>\n",
              "      <td>5.695911</td>\n",
              "      <td>2.350497</td>\n",
              "      <td>3.151030</td>\n",
              "      <td>4.196019</td>\n",
              "      <td>7.499816</td>\n",
              "      <td>3.197060</td>\n",
              "      <td>1.949057</td>\n",
              "      <td>1.955469</td>\n",
              "      <td>2.558617</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000487</td>\n",
              "      <td>0.016521</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000467</td>\n",
              "      <td>0.000301</td>\n",
              "      <td>0.068475</td>\n",
              "      <td>0.250073</td>\n",
              "      <td>0.250775</td>\n",
              "      <td>0.250968</td>\n",
              "      <td>0.248184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>30.753887</td>\n",
              "      <td>66.776044</td>\n",
              "      <td>19.732878</td>\n",
              "      <td>14.983054</td>\n",
              "      <td>43.879759</td>\n",
              "      <td>93.687390</td>\n",
              "      <td>16.887852</td>\n",
              "      <td>10.362398</td>\n",
              "      <td>10.418928</td>\n",
              "      <td>18.232781</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022074</td>\n",
              "      <td>0.127469</td>\n",
              "      <td>0.012659</td>\n",
              "      <td>0.021616</td>\n",
              "      <td>0.017333</td>\n",
              "      <td>0.252560</td>\n",
              "      <td>0.433057</td>\n",
              "      <td>0.433460</td>\n",
              "      <td>0.433572</td>\n",
              "      <td>0.431960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-12.727801</td>\n",
              "      <td>-27.666384</td>\n",
              "      <td>-0.364924</td>\n",
              "      <td>-0.561358</td>\n",
              "      <td>-17.560014</td>\n",
              "      <td>-39.123411</td>\n",
              "      <td>-7.110765</td>\n",
              "      <td>-15.738882</td>\n",
              "      <td>-15.843964</td>\n",
              "      <td>-230.189457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.188018</td>\n",
              "      <td>-0.189482</td>\n",
              "      <td>-0.206460</td>\n",
              "      <td>-0.059919</td>\n",
              "      <td>-0.159263</td>\n",
              "      <td>-0.137315</td>\n",
              "      <td>-0.052494</td>\n",
              "      <td>-0.186015</td>\n",
              "      <td>-0.186162</td>\n",
              "      <td>-0.199701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.811982</td>\n",
              "      <td>0.810518</td>\n",
              "      <td>0.793540</td>\n",
              "      <td>0.940081</td>\n",
              "      <td>0.840737</td>\n",
              "      <td>0.862685</td>\n",
              "      <td>0.947506</td>\n",
              "      <td>0.813985</td>\n",
              "      <td>0.813838</td>\n",
              "      <td>0.800299</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1132.659692</td>\n",
              "      <td>2484.308473</td>\n",
              "      <td>1310.202802</td>\n",
              "      <td>521.609218</td>\n",
              "      <td>1704.050447</td>\n",
              "      <td>3819.282006</td>\n",
              "      <td>710.228067</td>\n",
              "      <td>302.108907</td>\n",
              "      <td>304.159322</td>\n",
              "      <td>780.778457</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows √ó 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0              1              2              3    \\\n",
              "count  149748.000000  149748.000000  149748.000000  149748.000000   \n",
              "mean        3.313023       5.695911       2.350497       3.151030   \n",
              "std        30.753887      66.776044      19.732878      14.983054   \n",
              "min       -12.727801     -27.666384      -0.364924      -0.561358   \n",
              "25%        -0.188018      -0.189482      -0.206460      -0.059919   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.811982       0.810518       0.793540       0.940081   \n",
              "max      1132.659692    2484.308473    1310.202802     521.609218   \n",
              "\n",
              "                 4              5              6              7    \\\n",
              "count  149748.000000  149748.000000  149748.000000  149748.000000   \n",
              "mean        4.196019       7.499816       3.197060       1.949057   \n",
              "std        43.879759      93.687390      16.887852      10.362398   \n",
              "min       -17.560014     -39.123411      -7.110765     -15.738882   \n",
              "25%        -0.159263      -0.137315      -0.052494      -0.186015   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.840737       0.862685       0.947506       0.813985   \n",
              "max      1704.050447    3819.282006     710.228067     302.108907   \n",
              "\n",
              "                 8              9    ...            111            112  \\\n",
              "count  149748.000000  149748.000000  ...  149748.000000  149748.000000   \n",
              "mean        1.955469       2.558617  ...       0.000487       0.016521   \n",
              "std        10.418928      18.232781  ...       0.022074       0.127469   \n",
              "min       -15.843964    -230.189457  ...       0.000000       0.000000   \n",
              "25%        -0.186162      -0.199701  ...       0.000000       0.000000   \n",
              "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "75%         0.813838       0.800299  ...       0.000000       0.000000   \n",
              "max       304.159322     780.778457  ...       1.000000       1.000000   \n",
              "\n",
              "                 113            114            115            116  \\\n",
              "count  149748.000000  149748.000000  149748.000000  149748.000000   \n",
              "mean        0.000160       0.000467       0.000301       0.068475   \n",
              "std         0.012659       0.021616       0.017333       0.252560   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 117            118            119            120  \n",
              "count  149748.000000  149748.000000  149748.000000  149748.000000  \n",
              "mean        0.250073       0.250775       0.250968       0.248184  \n",
              "std         0.433057       0.433460       0.433572       0.431960  \n",
              "min         0.000000       0.000000       0.000000       0.000000  \n",
              "25%         0.000000       0.000000       0.000000       0.000000  \n",
              "50%         0.000000       0.000000       0.000000       0.000000  \n",
              "75%         1.000000       1.000000       1.000000       0.000000  \n",
              "max         1.000000       1.000000       1.000000       1.000000  \n",
              "\n",
              "[8 rows x 121 columns]"
            ]
          },
          "execution_count": 484,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(X_train_qtr_processed).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 485,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assets</th>\n",
              "      <th>AssetsCurrent</th>\n",
              "      <th>Cash</th>\n",
              "      <th>AssetsNoncurrent</th>\n",
              "      <th>Liabilities</th>\n",
              "      <th>LiabilitiesCurrent</th>\n",
              "      <th>LiabilitiesNoncurrent</th>\n",
              "      <th>Equity</th>\n",
              "      <th>HolderEquity</th>\n",
              "      <th>RetainedEarnings</th>\n",
              "      <th>...</th>\n",
              "      <th>CashProvidedByUsedInFinancingActivitiesDiscontinuedOperations</th>\n",
              "      <th>EffectOfExchangeRateFinal</th>\n",
              "      <th>CashPeriodIncreaseDecreaseIncludingExRateEffectFinal</th>\n",
              "      <th>GDP</th>\n",
              "      <th>interest_rate</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>median_cpi</th>\n",
              "      <th>market_cap</th>\n",
              "      <th>small_cap</th>\n",
              "      <th>micro_cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>1.497480e+05</td>\n",
              "      <td>149748.000000</td>\n",
              "      <td>149748.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.346934e+10</td>\n",
              "      <td>1.030280e+10</td>\n",
              "      <td>5.962491e+08</td>\n",
              "      <td>3.089584e+09</td>\n",
              "      <td>1.090559e+10</td>\n",
              "      <td>8.526148e+09</td>\n",
              "      <td>2.341270e+09</td>\n",
              "      <td>2.516776e+09</td>\n",
              "      <td>2.506996e+09</td>\n",
              "      <td>1.504429e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>-8.464088e+04</td>\n",
              "      <td>-2.729899e+06</td>\n",
              "      <td>4.206544e+07</td>\n",
              "      <td>2.480137</td>\n",
              "      <td>0.974715</td>\n",
              "      <td>5.471505</td>\n",
              "      <td>2.775681</td>\n",
              "      <td>7.204305e+03</td>\n",
              "      <td>0.679882</td>\n",
              "      <td>0.403278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.175290e+11</td>\n",
              "      <td>1.163598e+11</td>\n",
              "      <td>4.532583e+09</td>\n",
              "      <td>1.441559e+10</td>\n",
              "      <td>1.095733e+11</td>\n",
              "      <td>1.043875e+11</td>\n",
              "      <td>1.216521e+10</td>\n",
              "      <td>1.206360e+10</td>\n",
              "      <td>1.204771e+10</td>\n",
              "      <td>1.059973e+10</td>\n",
              "      <td>...</td>\n",
              "      <td>4.678280e+07</td>\n",
              "      <td>1.362826e+08</td>\n",
              "      <td>2.505025e+09</td>\n",
              "      <td>8.891386</td>\n",
              "      <td>1.351488</td>\n",
              "      <td>1.836366</td>\n",
              "      <td>1.328529</td>\n",
              "      <td>3.926514e+04</td>\n",
              "      <td>0.466523</td>\n",
              "      <td>0.490557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.783227e+10</td>\n",
              "      <td>-4.783227e+10</td>\n",
              "      <td>-2.747500e+07</td>\n",
              "      <td>-4.822030e+08</td>\n",
              "      <td>-4.342195e+10</td>\n",
              "      <td>-4.342195e+10</td>\n",
              "      <td>-5.084000e+09</td>\n",
              "      <td>-1.807500e+10</td>\n",
              "      <td>-1.807500e+10</td>\n",
              "      <td>-1.338050e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.929000e+09</td>\n",
              "      <td>-3.234200e+10</td>\n",
              "      <td>-1.736000e+11</td>\n",
              "      <td>-69.630993</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>-0.286064</td>\n",
              "      <td>5.317758e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.975850e+07</td>\n",
              "      <td>4.728050e+07</td>\n",
              "      <td>8.923750e+06</td>\n",
              "      <td>2.448958e+05</td>\n",
              "      <td>2.989975e+07</td>\n",
              "      <td>1.677496e+07</td>\n",
              "      <td>4.450000e+05</td>\n",
              "      <td>3.118881e+07</td>\n",
              "      <td>3.056750e+07</td>\n",
              "      <td>-9.913524e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.337525e+07</td>\n",
              "      <td>1.388811</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>1.961900</td>\n",
              "      <td>8.124002e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.082875e+08</td>\n",
              "      <td>3.774610e+08</td>\n",
              "      <td>5.634700e+07</td>\n",
              "      <td>5.789450e+07</td>\n",
              "      <td>4.276005e+08</td>\n",
              "      <td>1.697725e+08</td>\n",
              "      <td>3.825900e+07</td>\n",
              "      <td>2.477415e+08</td>\n",
              "      <td>2.458315e+08</td>\n",
              "      <td>1.696200e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-2.791500e+03</td>\n",
              "      <td>2.590671</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.452308</td>\n",
              "      <td>6.158901e+02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.911358e+09</td>\n",
              "      <td>1.789819e+09</td>\n",
              "      <td>2.386208e+08</td>\n",
              "      <td>9.623715e+08</td>\n",
              "      <td>2.527025e+09</td>\n",
              "      <td>1.130986e+09</td>\n",
              "      <td>7.207978e+08</td>\n",
              "      <td>1.195359e+09</td>\n",
              "      <td>1.186896e+09</td>\n",
              "      <td>4.822205e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.515524e+07</td>\n",
              "      <td>4.056326</td>\n",
              "      <td>1.510000</td>\n",
              "      <td>6.700000</td>\n",
              "      <td>2.966116</td>\n",
              "      <td>3.194766e+03</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.329380e+12</td>\n",
              "      <td>4.329380e+12</td>\n",
              "      <td>3.010060e+11</td>\n",
              "      <td>5.019120e+11</td>\n",
              "      <td>4.255655e+12</td>\n",
              "      <td>4.255655e+12</td>\n",
              "      <td>5.116530e+11</td>\n",
              "      <td>3.519540e+11</td>\n",
              "      <td>3.519540e+11</td>\n",
              "      <td>4.539270e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>1.199100e+10</td>\n",
              "      <td>9.155000e+09</td>\n",
              "      <td>2.639780e+11</td>\n",
              "      <td>45.706033</td>\n",
              "      <td>5.330000</td>\n",
              "      <td>14.700000</td>\n",
              "      <td>8.048036</td>\n",
              "      <td>2.974308e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows √ó 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Assets  AssetsCurrent          Cash  AssetsNoncurrent  \\\n",
              "count  1.497480e+05   1.497480e+05  1.497480e+05      1.497480e+05   \n",
              "mean   1.346934e+10   1.030280e+10  5.962491e+08      3.089584e+09   \n",
              "std    1.175290e+11   1.163598e+11  4.532583e+09      1.441559e+10   \n",
              "min   -4.783227e+10  -4.783227e+10 -2.747500e+07     -4.822030e+08   \n",
              "25%    8.975850e+07   4.728050e+07  8.923750e+06      2.448958e+05   \n",
              "50%    8.082875e+08   3.774610e+08  5.634700e+07      5.789450e+07   \n",
              "75%    3.911358e+09   1.789819e+09  2.386208e+08      9.623715e+08   \n",
              "max    4.329380e+12   4.329380e+12  3.010060e+11      5.019120e+11   \n",
              "\n",
              "        Liabilities  LiabilitiesCurrent  LiabilitiesNoncurrent        Equity  \\\n",
              "count  1.497480e+05        1.497480e+05           1.497480e+05  1.497480e+05   \n",
              "mean   1.090559e+10        8.526148e+09           2.341270e+09  2.516776e+09   \n",
              "std    1.095733e+11        1.043875e+11           1.216521e+10  1.206360e+10   \n",
              "min   -4.342195e+10       -4.342195e+10          -5.084000e+09 -1.807500e+10   \n",
              "25%    2.989975e+07        1.677496e+07           4.450000e+05  3.118881e+07   \n",
              "50%    4.276005e+08        1.697725e+08           3.825900e+07  2.477415e+08   \n",
              "75%    2.527025e+09        1.130986e+09           7.207978e+08  1.195359e+09   \n",
              "max    4.255655e+12        4.255655e+12           5.116530e+11  3.519540e+11   \n",
              "\n",
              "       HolderEquity  RetainedEarnings  ...  \\\n",
              "count  1.497480e+05      1.497480e+05  ...   \n",
              "mean   2.506996e+09      1.504429e+09  ...   \n",
              "std    1.204771e+10      1.059973e+10  ...   \n",
              "min   -1.807500e+10     -1.338050e+11  ...   \n",
              "25%    3.056750e+07     -9.913524e+07  ...   \n",
              "50%    2.458315e+08      1.696200e+07  ...   \n",
              "75%    1.186896e+09      4.822205e+08  ...   \n",
              "max    3.519540e+11      4.539270e+11  ...   \n",
              "\n",
              "       CashProvidedByUsedInFinancingActivitiesDiscontinuedOperations  \\\n",
              "count                                       1.497480e+05               \n",
              "mean                                       -8.464088e+04               \n",
              "std                                         4.678280e+07               \n",
              "min                                        -3.929000e+09               \n",
              "25%                                         0.000000e+00               \n",
              "50%                                         0.000000e+00               \n",
              "75%                                         0.000000e+00               \n",
              "max                                         1.199100e+10               \n",
              "\n",
              "       EffectOfExchangeRateFinal  \\\n",
              "count               1.497480e+05   \n",
              "mean               -2.729899e+06   \n",
              "std                 1.362826e+08   \n",
              "min                -3.234200e+10   \n",
              "25%                 0.000000e+00   \n",
              "50%                 0.000000e+00   \n",
              "75%                 0.000000e+00   \n",
              "max                 9.155000e+09   \n",
              "\n",
              "       CashPeriodIncreaseDecreaseIncludingExRateEffectFinal            GDP  \\\n",
              "count                                       1.497480e+05     149748.000000   \n",
              "mean                                        4.206544e+07          2.480137   \n",
              "std                                         2.505025e+09          8.891386   \n",
              "min                                        -1.736000e+11        -69.630993   \n",
              "25%                                        -1.337525e+07          1.388811   \n",
              "50%                                        -2.791500e+03          2.590671   \n",
              "75%                                         1.515524e+07          4.056326   \n",
              "max                                         2.639780e+11         45.706033   \n",
              "\n",
              "       interest_rate  unemployment_rate     median_cpi    market_cap  \\\n",
              "count  149748.000000      149748.000000  149748.000000  1.497480e+05   \n",
              "mean        0.974715           5.471505       2.775681  7.204305e+03   \n",
              "std         1.351488           1.836366       1.328529  3.926514e+04   \n",
              "min         0.050000           3.400000      -0.286064  5.317758e-06   \n",
              "25%         0.090000           3.900000       1.961900  8.124002e+01   \n",
              "50%         0.240000           5.000000       2.452308  6.158901e+02   \n",
              "75%         1.510000           6.700000       2.966116  3.194766e+03   \n",
              "max         5.330000          14.700000       8.048036  2.974308e+06   \n",
              "\n",
              "           small_cap      micro_cap  \n",
              "count  149748.000000  149748.000000  \n",
              "mean        0.679882       0.403278  \n",
              "std         0.466523       0.490557  \n",
              "min         0.000000       0.000000  \n",
              "25%         0.000000       0.000000  \n",
              "50%         1.000000       0.000000  \n",
              "75%         1.000000       1.000000  \n",
              "max         1.000000       1.000000  \n",
              "\n",
              "[8 rows x 45 columns]"
            ]
          },
          "execution_count": 485,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(X_train_qtr).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 486,
      "metadata": {
        "id": "TBpPlofv0SO6"
      },
      "outputs": [],
      "source": [
        "# Step 7 : then the test data\n",
        "#X_test_qtr_processed = preprocess_new_data(X_test_qtr, preprocessor_qtr)\n",
        "#X_test_yr_processed = preprocess_new_data(X_test_yr, preprocessor_yr)\n",
        "#X_test_2yr_processed = preprocess_new_data(X_test_2yr, preprocessor_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 487,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [11:11:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: ~/models/xgb_classifier_2024-09-12_11-11-49.pkl\n"
          ]
        }
      ],
      "source": [
        "# STEP 8 : Full set train!!\n",
        "model_qtr_xgb = fullset_train_xgb_and_save(X_train_qtr_processed, y_train_qtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 488,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [11:12:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: ~/models/xgb_classifier_2024-09-12_11-12-04.pkl\n"
          ]
        }
      ],
      "source": [
        "model_yr_xgb = fullset_train_xgb_and_save(X_train_yr_processed, y_train_yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 489,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [11:12:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: ~/models/xgb_classifier_2024-09-12_11-12-06.pkl\n"
          ]
        }
      ],
      "source": [
        "model_2yr_xgb = fullset_train_xgb_and_save(X_train_2yr_processed, y_train_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training logistic_regression: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:04 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of iterations: [352]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:19 left: 00:00]\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:19 left: 00:00]\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:19 left: 00:00]\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:19 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.6632, precision: 0.3379, recall: 0.5131, f1: 0.4002\n",
            "Model saved to: ~/models/logistic_regression_2024-09-11_16-02-30.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 8 :Train for quarterly (frequency=1), yearly (frequency=4), and 2-year (frequency=8) predictions\n",
        "y_pred_qtr_log_reg, model_qtr_log_reg = train_logistic_regression_and_save(X_train_qtr_processed, y_train_qtr, X_test_qtr_processed, y_test_qtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training logistic_regression: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:01 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of iterations: [140]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:07 left: 00:00]\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.6606, precision: 0.3430, recall: 0.5238, f1: 0.4065\n",
            "Model saved to: ~/models/logistic_regression_2024-09-11_11-59-14.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_yr_log_reg, model_yr_log_reg = train_logistic_regression_and_save(X_train_yr_processed, y_train_yr, X_test_yr_processed, y_test_yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOMfwVi_1GDf",
        "outputId": "c2be492d-a575-47fc-c9c9-0ee5e3352a01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training logistic_regression: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of iterations: [532]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:13 left: 00:00]\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:13 left: 00:00]\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:13 left: 00:00]\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:13 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.6596, precision: 0.3333, recall: 0.5061, f1: 0.3966\n",
            "Model saved to: ~/models/logistic_regression_2024-09-11_12-01-22.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_2yr_log_reg, model_2yr = train_logistic_regression_and_save(X_train_2yr_processed, y_train_2yr, X_test_2yr_processed, y_test_2yr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-logloss:0.60780\n",
            "[1]\tvalidation_0-logloss:0.60730\n",
            "[2]\tvalidation_0-logloss:0.60681\n",
            "[3]\tvalidation_0-logloss:0.60632\n",
            "[4]\tvalidation_0-logloss:0.60584\n",
            "[5]\tvalidation_0-logloss:0.60538\n",
            "[6]\tvalidation_0-logloss:0.60492\n",
            "[7]\tvalidation_0-logloss:0.60446\n",
            "[8]\tvalidation_0-logloss:0.60402\n",
            "[9]\tvalidation_0-logloss:0.60359\n",
            "[10]\tvalidation_0-logloss:0.60316\n",
            "[11]\tvalidation_0-logloss:0.60275\n",
            "[12]\tvalidation_0-logloss:0.60234\n",
            "[13]\tvalidation_0-logloss:0.60194\n",
            "[14]\tvalidation_0-logloss:0.60155\n",
            "[15]\tvalidation_0-logloss:0.60118\n",
            "[16]\tvalidation_0-logloss:0.60080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17]\tvalidation_0-logloss:0.60043\n",
            "[18]\tvalidation_0-logloss:0.60006\n",
            "[19]\tvalidation_0-logloss:0.59972\n",
            "[20]\tvalidation_0-logloss:0.59937\n",
            "[21]\tvalidation_0-logloss:0.59901\n",
            "[22]\tvalidation_0-logloss:0.59869\n",
            "[23]\tvalidation_0-logloss:0.59835\n",
            "[24]\tvalidation_0-logloss:0.59802\n",
            "[25]\tvalidation_0-logloss:0.59768\n",
            "[26]\tvalidation_0-logloss:0.59738\n",
            "[27]\tvalidation_0-logloss:0.59707\n",
            "[28]\tvalidation_0-logloss:0.59677\n",
            "[29]\tvalidation_0-logloss:0.59645\n",
            "[30]\tvalidation_0-logloss:0.59616\n",
            "[31]\tvalidation_0-logloss:0.59586\n",
            "[32]\tvalidation_0-logloss:0.59558\n",
            "[33]\tvalidation_0-logloss:0.59529\n",
            "[34]\tvalidation_0-logloss:0.59500\n",
            "[35]\tvalidation_0-logloss:0.59471\n",
            "[36]\tvalidation_0-logloss:0.59446\n",
            "[37]\tvalidation_0-logloss:0.59418\n",
            "[38]\tvalidation_0-logloss:0.59392\n",
            "[39]\tvalidation_0-logloss:0.59367\n",
            "[40]\tvalidation_0-logloss:0.59340\n",
            "[41]\tvalidation_0-logloss:0.59316\n",
            "[42]\tvalidation_0-logloss:0.59291\n",
            "[43]\tvalidation_0-logloss:0.59265\n",
            "[44]\tvalidation_0-logloss:0.59242\n",
            "[45]\tvalidation_0-logloss:0.59217\n",
            "[46]\tvalidation_0-logloss:0.59192\n",
            "[47]\tvalidation_0-logloss:0.59168\n",
            "[48]\tvalidation_0-logloss:0.59144\n",
            "[49]\tvalidation_0-logloss:0.59121\n",
            "[50]\tvalidation_0-logloss:0.59097\n",
            "[51]\tvalidation_0-logloss:0.59075\n",
            "[52]\tvalidation_0-logloss:0.59053\n",
            "[53]\tvalidation_0-logloss:0.59032\n",
            "[54]\tvalidation_0-logloss:0.59010\n",
            "[55]\tvalidation_0-logloss:0.58988\n",
            "[56]\tvalidation_0-logloss:0.58967\n",
            "[57]\tvalidation_0-logloss:0.58948\n",
            "[58]\tvalidation_0-logloss:0.58927\n",
            "[59]\tvalidation_0-logloss:0.58906\n",
            "[60]\tvalidation_0-logloss:0.58886\n",
            "[61]\tvalidation_0-logloss:0.58866\n",
            "[62]\tvalidation_0-logloss:0.58847\n",
            "[63]\tvalidation_0-logloss:0.58828\n",
            "[64]\tvalidation_0-logloss:0.58809\n",
            "[65]\tvalidation_0-logloss:0.58792\n",
            "[66]\tvalidation_0-logloss:0.58774\n",
            "[67]\tvalidation_0-logloss:0.58756\n",
            "[68]\tvalidation_0-logloss:0.58739\n",
            "[69]\tvalidation_0-logloss:0.58723\n",
            "[70]\tvalidation_0-logloss:0.58706\n",
            "[71]\tvalidation_0-logloss:0.58687\n",
            "[72]\tvalidation_0-logloss:0.58671\n",
            "[73]\tvalidation_0-logloss:0.58656\n",
            "[74]\tvalidation_0-logloss:0.58640\n",
            "[75]\tvalidation_0-logloss:0.58625\n",
            "[76]\tvalidation_0-logloss:0.58609\n",
            "[77]\tvalidation_0-logloss:0.58595\n",
            "[78]\tvalidation_0-logloss:0.58580\n",
            "[79]\tvalidation_0-logloss:0.58562\n",
            "[80]\tvalidation_0-logloss:0.58546\n",
            "[81]\tvalidation_0-logloss:0.58533\n",
            "[82]\tvalidation_0-logloss:0.58517\n",
            "[83]\tvalidation_0-logloss:0.58502\n",
            "[84]\tvalidation_0-logloss:0.58488\n",
            "[85]\tvalidation_0-logloss:0.58473\n",
            "[86]\tvalidation_0-logloss:0.58458\n",
            "[87]\tvalidation_0-logloss:0.58443\n",
            "[88]\tvalidation_0-logloss:0.58427\n",
            "[89]\tvalidation_0-logloss:0.58415\n",
            "[90]\tvalidation_0-logloss:0.58402\n",
            "[91]\tvalidation_0-logloss:0.58386\n",
            "[92]\tvalidation_0-logloss:0.58371\n",
            "[93]\tvalidation_0-logloss:0.58359\n",
            "[94]\tvalidation_0-logloss:0.58346\n",
            "[95]\tvalidation_0-logloss:0.58332\n",
            "[96]\tvalidation_0-logloss:0.58321\n",
            "[97]\tvalidation_0-logloss:0.58309\n",
            "[98]\tvalidation_0-logloss:0.58296\n",
            "[99]\tvalidation_0-logloss:0.58281\n",
            "[100]\tvalidation_0-logloss:0.58271\n",
            "[101]\tvalidation_0-logloss:0.58259\n",
            "[102]\tvalidation_0-logloss:0.58247\n",
            "[103]\tvalidation_0-logloss:0.58236\n",
            "[104]\tvalidation_0-logloss:0.58226\n",
            "[105]\tvalidation_0-logloss:0.58213\n",
            "[106]\tvalidation_0-logloss:0.58200\n",
            "[107]\tvalidation_0-logloss:0.58190\n",
            "[108]\tvalidation_0-logloss:0.58180\n",
            "[109]\tvalidation_0-logloss:0.58167\n",
            "[110]\tvalidation_0-logloss:0.58155\n",
            "[111]\tvalidation_0-logloss:0.58143\n",
            "[112]\tvalidation_0-logloss:0.58133\n",
            "[113]\tvalidation_0-logloss:0.58121\n",
            "[114]\tvalidation_0-logloss:0.58113\n",
            "[115]\tvalidation_0-logloss:0.58102\n",
            "[116]\tvalidation_0-logloss:0.58090\n",
            "[117]\tvalidation_0-logloss:0.58081\n",
            "[118]\tvalidation_0-logloss:0.58071\n",
            "[119]\tvalidation_0-logloss:0.58060\n",
            "[120]\tvalidation_0-logloss:0.58051\n",
            "[121]\tvalidation_0-logloss:0.58040\n",
            "[122]\tvalidation_0-logloss:0.58032\n",
            "[123]\tvalidation_0-logloss:0.58023\n",
            "[124]\tvalidation_0-logloss:0.58014\n",
            "[125]\tvalidation_0-logloss:0.58002\n",
            "[126]\tvalidation_0-logloss:0.57991\n",
            "[127]\tvalidation_0-logloss:0.57984\n",
            "[128]\tvalidation_0-logloss:0.57972\n",
            "[129]\tvalidation_0-logloss:0.57961\n",
            "[130]\tvalidation_0-logloss:0.57953\n",
            "[131]\tvalidation_0-logloss:0.57943\n",
            "[132]\tvalidation_0-logloss:0.57935\n",
            "[133]\tvalidation_0-logloss:0.57927\n",
            "[134]\tvalidation_0-logloss:0.57916\n",
            "[135]\tvalidation_0-logloss:0.57909\n",
            "[136]\tvalidation_0-logloss:0.57897\n",
            "[137]\tvalidation_0-logloss:0.57889\n",
            "[138]\tvalidation_0-logloss:0.57881\n",
            "[139]\tvalidation_0-logloss:0.57873\n",
            "[140]\tvalidation_0-logloss:0.57863\n",
            "[141]\tvalidation_0-logloss:0.57855\n",
            "[142]\tvalidation_0-logloss:0.57847\n",
            "[143]\tvalidation_0-logloss:0.57839\n",
            "[144]\tvalidation_0-logloss:0.57831\n",
            "[145]\tvalidation_0-logloss:0.57819\n",
            "[146]\tvalidation_0-logloss:0.57814\n",
            "[147]\tvalidation_0-logloss:0.57803\n",
            "[148]\tvalidation_0-logloss:0.57791\n",
            "[149]\tvalidation_0-logloss:0.57785\n",
            "[150]\tvalidation_0-logloss:0.57778\n",
            "[151]\tvalidation_0-logloss:0.57770\n",
            "[152]\tvalidation_0-logloss:0.57763\n",
            "[153]\tvalidation_0-logloss:0.57755\n",
            "[154]\tvalidation_0-logloss:0.57749\n",
            "[155]\tvalidation_0-logloss:0.57738\n",
            "[156]\tvalidation_0-logloss:0.57727\n",
            "[157]\tvalidation_0-logloss:0.57717\n",
            "[158]\tvalidation_0-logloss:0.57709\n",
            "[159]\tvalidation_0-logloss:0.57703\n",
            "[160]\tvalidation_0-logloss:0.57692\n",
            "[161]\tvalidation_0-logloss:0.57685\n",
            "[162]\tvalidation_0-logloss:0.57674\n",
            "[163]\tvalidation_0-logloss:0.57669\n",
            "[164]\tvalidation_0-logloss:0.57658\n",
            "[165]\tvalidation_0-logloss:0.57652\n",
            "[166]\tvalidation_0-logloss:0.57642\n",
            "[167]\tvalidation_0-logloss:0.57637\n",
            "[168]\tvalidation_0-logloss:0.57631\n",
            "[169]\tvalidation_0-logloss:0.57621\n",
            "[170]\tvalidation_0-logloss:0.57615\n",
            "[171]\tvalidation_0-logloss:0.57605\n",
            "[172]\tvalidation_0-logloss:0.57600\n",
            "[173]\tvalidation_0-logloss:0.57590\n",
            "[174]\tvalidation_0-logloss:0.57581\n",
            "[175]\tvalidation_0-logloss:0.57572\n",
            "[176]\tvalidation_0-logloss:0.57566\n",
            "[177]\tvalidation_0-logloss:0.57562\n",
            "[178]\tvalidation_0-logloss:0.57553\n",
            "[179]\tvalidation_0-logloss:0.57544\n",
            "[180]\tvalidation_0-logloss:0.57538\n",
            "[181]\tvalidation_0-logloss:0.57533\n",
            "[182]\tvalidation_0-logloss:0.57524\n",
            "[183]\tvalidation_0-logloss:0.57520\n",
            "[184]\tvalidation_0-logloss:0.57516\n",
            "[185]\tvalidation_0-logloss:0.57507\n",
            "[186]\tvalidation_0-logloss:0.57504\n",
            "[187]\tvalidation_0-logloss:0.57496\n",
            "[188]\tvalidation_0-logloss:0.57490\n",
            "[189]\tvalidation_0-logloss:0.57484\n",
            "[190]\tvalidation_0-logloss:0.57477\n",
            "[191]\tvalidation_0-logloss:0.57472\n",
            "[192]\tvalidation_0-logloss:0.57469\n",
            "[193]\tvalidation_0-logloss:0.57464\n",
            "[194]\tvalidation_0-logloss:0.57457\n",
            "[195]\tvalidation_0-logloss:0.57449\n",
            "[196]\tvalidation_0-logloss:0.57446\n",
            "[197]\tvalidation_0-logloss:0.57441\n",
            "[198]\tvalidation_0-logloss:0.57438\n",
            "[199]\tvalidation_0-logloss:0.57431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (precision):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (recall):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (f1):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7081, precision: 0.6512, recall: 0.0305, f1: 0.0579\n",
            "Model saved to: ~/models/xgb_classifier_2024-09-11_23-42-28.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_qtr_xgb, model_qtr_xgb = train_xgb_and_save(X_train_qtr_processed, y_train_qtr, X_test_qtr_processed, y_test_qtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-logloss:0.61073\n",
            "[1]\tvalidation_0-logloss:0.61021\n",
            "[2]\tvalidation_0-logloss:0.60971\n",
            "[3]\tvalidation_0-logloss:0.60922\n",
            "[4]\tvalidation_0-logloss:0.60873\n",
            "[5]\tvalidation_0-logloss:0.60827\n",
            "[6]\tvalidation_0-logloss:0.60780\n",
            "[7]\tvalidation_0-logloss:0.60734\n",
            "[8]\tvalidation_0-logloss:0.60690\n",
            "[9]\tvalidation_0-logloss:0.60645\n",
            "[10]\tvalidation_0-logloss:0.60601\n",
            "[11]\tvalidation_0-logloss:0.60559\n",
            "[12]\tvalidation_0-logloss:0.60517\n",
            "[13]\tvalidation_0-logloss:0.60476\n",
            "[14]\tvalidation_0-logloss:0.60436\n",
            "[15]\tvalidation_0-logloss:0.60397\n",
            "[16]\tvalidation_0-logloss:0.60358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:42:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17]\tvalidation_0-logloss:0.60320\n",
            "[18]\tvalidation_0-logloss:0.60283\n",
            "[19]\tvalidation_0-logloss:0.60247\n",
            "[20]\tvalidation_0-logloss:0.60211\n",
            "[21]\tvalidation_0-logloss:0.60176\n",
            "[22]\tvalidation_0-logloss:0.60142\n",
            "[23]\tvalidation_0-logloss:0.60108\n",
            "[24]\tvalidation_0-logloss:0.60076\n",
            "[25]\tvalidation_0-logloss:0.60043\n",
            "[26]\tvalidation_0-logloss:0.60012\n",
            "[27]\tvalidation_0-logloss:0.59982\n",
            "[28]\tvalidation_0-logloss:0.59952\n",
            "[29]\tvalidation_0-logloss:0.59922\n",
            "[30]\tvalidation_0-logloss:0.59893\n",
            "[31]\tvalidation_0-logloss:0.59864\n",
            "[32]\tvalidation_0-logloss:0.59837\n",
            "[33]\tvalidation_0-logloss:0.59806\n",
            "[34]\tvalidation_0-logloss:0.59780\n",
            "[35]\tvalidation_0-logloss:0.59750\n",
            "[36]\tvalidation_0-logloss:0.59721\n",
            "[37]\tvalidation_0-logloss:0.59692\n",
            "[38]\tvalidation_0-logloss:0.59666\n",
            "[39]\tvalidation_0-logloss:0.59638\n",
            "[40]\tvalidation_0-logloss:0.59612\n",
            "[41]\tvalidation_0-logloss:0.59587\n",
            "[42]\tvalidation_0-logloss:0.59562\n",
            "[43]\tvalidation_0-logloss:0.59535\n",
            "[44]\tvalidation_0-logloss:0.59511\n",
            "[45]\tvalidation_0-logloss:0.59485\n",
            "[46]\tvalidation_0-logloss:0.59461\n",
            "[47]\tvalidation_0-logloss:0.59438\n",
            "[48]\tvalidation_0-logloss:0.59412\n",
            "[49]\tvalidation_0-logloss:0.59389\n",
            "[50]\tvalidation_0-logloss:0.59367\n",
            "[51]\tvalidation_0-logloss:0.59345\n",
            "[52]\tvalidation_0-logloss:0.59323\n",
            "[53]\tvalidation_0-logloss:0.59302\n",
            "[54]\tvalidation_0-logloss:0.59278\n",
            "[55]\tvalidation_0-logloss:0.59258\n",
            "[56]\tvalidation_0-logloss:0.59237\n",
            "[57]\tvalidation_0-logloss:0.59215\n",
            "[58]\tvalidation_0-logloss:0.59194\n",
            "[59]\tvalidation_0-logloss:0.59172\n",
            "[60]\tvalidation_0-logloss:0.59153\n",
            "[61]\tvalidation_0-logloss:0.59135\n",
            "[62]\tvalidation_0-logloss:0.59115\n",
            "[63]\tvalidation_0-logloss:0.59096\n",
            "[64]\tvalidation_0-logloss:0.59079\n",
            "[65]\tvalidation_0-logloss:0.59061\n",
            "[66]\tvalidation_0-logloss:0.59040\n",
            "[67]\tvalidation_0-logloss:0.59023\n",
            "[68]\tvalidation_0-logloss:0.59003\n",
            "[69]\tvalidation_0-logloss:0.58983\n",
            "[70]\tvalidation_0-logloss:0.58967\n",
            "[71]\tvalidation_0-logloss:0.58947\n",
            "[72]\tvalidation_0-logloss:0.58930\n",
            "[73]\tvalidation_0-logloss:0.58911\n",
            "[74]\tvalidation_0-logloss:0.58893\n",
            "[75]\tvalidation_0-logloss:0.58879\n",
            "[76]\tvalidation_0-logloss:0.58860\n",
            "[77]\tvalidation_0-logloss:0.58842\n",
            "[78]\tvalidation_0-logloss:0.58829\n",
            "[79]\tvalidation_0-logloss:0.58812\n",
            "[80]\tvalidation_0-logloss:0.58796\n",
            "[81]\tvalidation_0-logloss:0.58777\n",
            "[82]\tvalidation_0-logloss:0.58763\n",
            "[83]\tvalidation_0-logloss:0.58750\n",
            "[84]\tvalidation_0-logloss:0.58736\n",
            "[85]\tvalidation_0-logloss:0.58718\n",
            "[86]\tvalidation_0-logloss:0.58702\n",
            "[87]\tvalidation_0-logloss:0.58690\n",
            "[88]\tvalidation_0-logloss:0.58672\n",
            "[89]\tvalidation_0-logloss:0.58655\n",
            "[90]\tvalidation_0-logloss:0.58641\n",
            "[91]\tvalidation_0-logloss:0.58627\n",
            "[92]\tvalidation_0-logloss:0.58611\n",
            "[93]\tvalidation_0-logloss:0.58598\n",
            "[94]\tvalidation_0-logloss:0.58586\n",
            "[95]\tvalidation_0-logloss:0.58575\n",
            "[96]\tvalidation_0-logloss:0.58559\n",
            "[97]\tvalidation_0-logloss:0.58545\n",
            "[98]\tvalidation_0-logloss:0.58530\n",
            "[99]\tvalidation_0-logloss:0.58517\n",
            "[100]\tvalidation_0-logloss:0.58501\n",
            "[101]\tvalidation_0-logloss:0.58488\n",
            "[102]\tvalidation_0-logloss:0.58474\n",
            "[103]\tvalidation_0-logloss:0.58464\n",
            "[104]\tvalidation_0-logloss:0.58451\n",
            "[105]\tvalidation_0-logloss:0.58440\n",
            "[106]\tvalidation_0-logloss:0.58428\n",
            "[107]\tvalidation_0-logloss:0.58418\n",
            "[108]\tvalidation_0-logloss:0.58404\n",
            "[109]\tvalidation_0-logloss:0.58393\n",
            "[110]\tvalidation_0-logloss:0.58379\n",
            "[111]\tvalidation_0-logloss:0.58366\n",
            "[112]\tvalidation_0-logloss:0.58355\n",
            "[113]\tvalidation_0-logloss:0.58345\n",
            "[114]\tvalidation_0-logloss:0.58333\n",
            "[115]\tvalidation_0-logloss:0.58323\n",
            "[116]\tvalidation_0-logloss:0.58312\n",
            "[117]\tvalidation_0-logloss:0.58299\n",
            "[118]\tvalidation_0-logloss:0.58288\n",
            "[119]\tvalidation_0-logloss:0.58278\n",
            "[120]\tvalidation_0-logloss:0.58267\n",
            "[121]\tvalidation_0-logloss:0.58258\n",
            "[122]\tvalidation_0-logloss:0.58244\n",
            "[123]\tvalidation_0-logloss:0.58232\n",
            "[124]\tvalidation_0-logloss:0.58224\n",
            "[125]\tvalidation_0-logloss:0.58216\n",
            "[126]\tvalidation_0-logloss:0.58207\n",
            "[127]\tvalidation_0-logloss:0.58199\n",
            "[128]\tvalidation_0-logloss:0.58190\n",
            "[129]\tvalidation_0-logloss:0.58181\n",
            "[130]\tvalidation_0-logloss:0.58170\n",
            "[131]\tvalidation_0-logloss:0.58158\n",
            "[132]\tvalidation_0-logloss:0.58150\n",
            "[133]\tvalidation_0-logloss:0.58143\n",
            "[134]\tvalidation_0-logloss:0.58135\n",
            "[135]\tvalidation_0-logloss:0.58126\n",
            "[136]\tvalidation_0-logloss:0.58114\n",
            "[137]\tvalidation_0-logloss:0.58103\n",
            "[138]\tvalidation_0-logloss:0.58096\n",
            "[139]\tvalidation_0-logloss:0.58087\n",
            "[140]\tvalidation_0-logloss:0.58077\n",
            "[141]\tvalidation_0-logloss:0.58070\n",
            "[142]\tvalidation_0-logloss:0.58059\n",
            "[143]\tvalidation_0-logloss:0.58052\n",
            "[144]\tvalidation_0-logloss:0.58042\n",
            "[145]\tvalidation_0-logloss:0.58035\n",
            "[146]\tvalidation_0-logloss:0.58025\n",
            "[147]\tvalidation_0-logloss:0.58017\n",
            "[148]\tvalidation_0-logloss:0.58010\n",
            "[149]\tvalidation_0-logloss:0.58003\n",
            "[150]\tvalidation_0-logloss:0.57995\n",
            "[151]\tvalidation_0-logloss:0.57987\n",
            "[152]\tvalidation_0-logloss:0.57978\n",
            "[153]\tvalidation_0-logloss:0.57972\n",
            "[154]\tvalidation_0-logloss:0.57966\n",
            "[155]\tvalidation_0-logloss:0.57958\n",
            "[156]\tvalidation_0-logloss:0.57951\n",
            "[157]\tvalidation_0-logloss:0.57946\n",
            "[158]\tvalidation_0-logloss:0.57939\n",
            "[159]\tvalidation_0-logloss:0.57934\n",
            "[160]\tvalidation_0-logloss:0.57928\n",
            "[161]\tvalidation_0-logloss:0.57921\n",
            "[162]\tvalidation_0-logloss:0.57914\n",
            "[163]\tvalidation_0-logloss:0.57907\n",
            "[164]\tvalidation_0-logloss:0.57899\n",
            "[165]\tvalidation_0-logloss:0.57892\n",
            "[166]\tvalidation_0-logloss:0.57887\n",
            "[167]\tvalidation_0-logloss:0.57881\n",
            "[168]\tvalidation_0-logloss:0.57871\n",
            "[169]\tvalidation_0-logloss:0.57866\n",
            "[170]\tvalidation_0-logloss:0.57861\n",
            "[171]\tvalidation_0-logloss:0.57849\n",
            "[172]\tvalidation_0-logloss:0.57840\n",
            "[173]\tvalidation_0-logloss:0.57834\n",
            "[174]\tvalidation_0-logloss:0.57828\n",
            "[175]\tvalidation_0-logloss:0.57819\n",
            "[176]\tvalidation_0-logloss:0.57816\n",
            "[177]\tvalidation_0-logloss:0.57804\n",
            "[178]\tvalidation_0-logloss:0.57799\n",
            "[179]\tvalidation_0-logloss:0.57789\n",
            "[180]\tvalidation_0-logloss:0.57785\n",
            "[181]\tvalidation_0-logloss:0.57779\n",
            "[182]\tvalidation_0-logloss:0.57775\n",
            "[183]\tvalidation_0-logloss:0.57765\n",
            "[184]\tvalidation_0-logloss:0.57760\n",
            "[185]\tvalidation_0-logloss:0.57753\n",
            "[186]\tvalidation_0-logloss:0.57744\n",
            "[187]\tvalidation_0-logloss:0.57736\n",
            "[188]\tvalidation_0-logloss:0.57730\n",
            "[189]\tvalidation_0-logloss:0.57722\n",
            "[190]\tvalidation_0-logloss:0.57716\n",
            "[191]\tvalidation_0-logloss:0.57713\n",
            "[192]\tvalidation_0-logloss:0.57707\n",
            "[193]\tvalidation_0-logloss:0.57698\n",
            "[194]\tvalidation_0-logloss:0.57695\n",
            "[195]\tvalidation_0-logloss:0.57686\n",
            "[196]\tvalidation_0-logloss:0.57682\n",
            "[197]\tvalidation_0-logloss:0.57674\n",
            "[198]\tvalidation_0-logloss:0.57668\n",
            "[199]\tvalidation_0-logloss:0.57660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (precision):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (recall):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (f1):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7091, precision: 0.6842, recall: 0.0282, f1: 0.0538\n",
            "Model saved to: ~/models/xgb_classifier_2024-09-11_23-43-26.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_yr_xgb, model_yr_xgb = train_xgb_and_save(X_train_yr_processed, y_train_yr, X_test_yr_processed, y_test_yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-logloss:0.60455\n",
            "[1]\tvalidation_0-logloss:0.60405\n",
            "[2]\tvalidation_0-logloss:0.60357\n",
            "[3]\tvalidation_0-logloss:0.60310\n",
            "[4]\tvalidation_0-logloss:0.60263\n",
            "[5]\tvalidation_0-logloss:0.60217\n",
            "[6]\tvalidation_0-logloss:0.60172\n",
            "[7]\tvalidation_0-logloss:0.60129\n",
            "[8]\tvalidation_0-logloss:0.60086\n",
            "[9]\tvalidation_0-logloss:0.60044\n",
            "[10]\tvalidation_0-logloss:0.60002\n",
            "[11]\tvalidation_0-logloss:0.59961\n",
            "[12]\tvalidation_0-logloss:0.59920\n",
            "[13]\tvalidation_0-logloss:0.59881\n",
            "[14]\tvalidation_0-logloss:0.59841\n",
            "[15]\tvalidation_0-logloss:0.59802\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16]\tvalidation_0-logloss:0.59765\n",
            "[17]\tvalidation_0-logloss:0.59727\n",
            "[18]\tvalidation_0-logloss:0.59690\n",
            "[19]\tvalidation_0-logloss:0.59655\n",
            "[20]\tvalidation_0-logloss:0.59620\n",
            "[21]\tvalidation_0-logloss:0.59585\n",
            "[22]\tvalidation_0-logloss:0.59551\n",
            "[23]\tvalidation_0-logloss:0.59517\n",
            "[24]\tvalidation_0-logloss:0.59485\n",
            "[25]\tvalidation_0-logloss:0.59452\n",
            "[26]\tvalidation_0-logloss:0.59419\n",
            "[27]\tvalidation_0-logloss:0.59388\n",
            "[28]\tvalidation_0-logloss:0.59356\n",
            "[29]\tvalidation_0-logloss:0.59325\n",
            "[30]\tvalidation_0-logloss:0.59295\n",
            "[31]\tvalidation_0-logloss:0.59265\n",
            "[32]\tvalidation_0-logloss:0.59235\n",
            "[33]\tvalidation_0-logloss:0.59207\n",
            "[34]\tvalidation_0-logloss:0.59179\n",
            "[35]\tvalidation_0-logloss:0.59152\n",
            "[36]\tvalidation_0-logloss:0.59124\n",
            "[37]\tvalidation_0-logloss:0.59097\n",
            "[38]\tvalidation_0-logloss:0.59071\n",
            "[39]\tvalidation_0-logloss:0.59047\n",
            "[40]\tvalidation_0-logloss:0.59021\n",
            "[41]\tvalidation_0-logloss:0.58996\n",
            "[42]\tvalidation_0-logloss:0.58969\n",
            "[43]\tvalidation_0-logloss:0.58946\n",
            "[44]\tvalidation_0-logloss:0.58922\n",
            "[45]\tvalidation_0-logloss:0.58898\n",
            "[46]\tvalidation_0-logloss:0.58874\n",
            "[47]\tvalidation_0-logloss:0.58853\n",
            "[48]\tvalidation_0-logloss:0.58830\n",
            "[49]\tvalidation_0-logloss:0.58806\n",
            "[50]\tvalidation_0-logloss:0.58785\n",
            "[51]\tvalidation_0-logloss:0.58763\n",
            "[52]\tvalidation_0-logloss:0.58739\n",
            "[53]\tvalidation_0-logloss:0.58716\n",
            "[54]\tvalidation_0-logloss:0.58693\n",
            "[55]\tvalidation_0-logloss:0.58671\n",
            "[56]\tvalidation_0-logloss:0.58652\n",
            "[57]\tvalidation_0-logloss:0.58631\n",
            "[58]\tvalidation_0-logloss:0.58608\n",
            "[59]\tvalidation_0-logloss:0.58587\n",
            "[60]\tvalidation_0-logloss:0.58570\n",
            "[61]\tvalidation_0-logloss:0.58549\n",
            "[62]\tvalidation_0-logloss:0.58528\n",
            "[63]\tvalidation_0-logloss:0.58508\n",
            "[64]\tvalidation_0-logloss:0.58488\n",
            "[65]\tvalidation_0-logloss:0.58469\n",
            "[66]\tvalidation_0-logloss:0.58450\n",
            "[67]\tvalidation_0-logloss:0.58430\n",
            "[68]\tvalidation_0-logloss:0.58412\n",
            "[69]\tvalidation_0-logloss:0.58393\n",
            "[70]\tvalidation_0-logloss:0.58376\n",
            "[71]\tvalidation_0-logloss:0.58359\n",
            "[72]\tvalidation_0-logloss:0.58341\n",
            "[73]\tvalidation_0-logloss:0.58323\n",
            "[74]\tvalidation_0-logloss:0.58307\n",
            "[75]\tvalidation_0-logloss:0.58291\n",
            "[76]\tvalidation_0-logloss:0.58274\n",
            "[77]\tvalidation_0-logloss:0.58259\n",
            "[78]\tvalidation_0-logloss:0.58240\n",
            "[79]\tvalidation_0-logloss:0.58224\n",
            "[80]\tvalidation_0-logloss:0.58205\n",
            "[81]\tvalidation_0-logloss:0.58187\n",
            "[82]\tvalidation_0-logloss:0.58169\n",
            "[83]\tvalidation_0-logloss:0.58154\n",
            "[84]\tvalidation_0-logloss:0.58140\n",
            "[85]\tvalidation_0-logloss:0.58125\n",
            "[86]\tvalidation_0-logloss:0.58108\n",
            "[87]\tvalidation_0-logloss:0.58092\n",
            "[88]\tvalidation_0-logloss:0.58075\n",
            "[89]\tvalidation_0-logloss:0.58059\n",
            "[90]\tvalidation_0-logloss:0.58046\n",
            "[91]\tvalidation_0-logloss:0.58033\n",
            "[92]\tvalidation_0-logloss:0.58017\n",
            "[93]\tvalidation_0-logloss:0.58003\n",
            "[94]\tvalidation_0-logloss:0.57989\n",
            "[95]\tvalidation_0-logloss:0.57978\n",
            "[96]\tvalidation_0-logloss:0.57965\n",
            "[97]\tvalidation_0-logloss:0.57951\n",
            "[98]\tvalidation_0-logloss:0.57937\n",
            "[99]\tvalidation_0-logloss:0.57925\n",
            "[100]\tvalidation_0-logloss:0.57912\n",
            "[101]\tvalidation_0-logloss:0.57900\n",
            "[102]\tvalidation_0-logloss:0.57887\n",
            "[103]\tvalidation_0-logloss:0.57875\n",
            "[104]\tvalidation_0-logloss:0.57863\n",
            "[105]\tvalidation_0-logloss:0.57853\n",
            "[106]\tvalidation_0-logloss:0.57841\n",
            "[107]\tvalidation_0-logloss:0.57829\n",
            "[108]\tvalidation_0-logloss:0.57816\n",
            "[109]\tvalidation_0-logloss:0.57803\n",
            "[110]\tvalidation_0-logloss:0.57793\n",
            "[111]\tvalidation_0-logloss:0.57784\n",
            "[112]\tvalidation_0-logloss:0.57773\n",
            "[113]\tvalidation_0-logloss:0.57760\n",
            "[114]\tvalidation_0-logloss:0.57748\n",
            "[115]\tvalidation_0-logloss:0.57740\n",
            "[116]\tvalidation_0-logloss:0.57729\n",
            "[117]\tvalidation_0-logloss:0.57720\n",
            "[118]\tvalidation_0-logloss:0.57709\n",
            "[119]\tvalidation_0-logloss:0.57698\n",
            "[120]\tvalidation_0-logloss:0.57688\n",
            "[121]\tvalidation_0-logloss:0.57676\n",
            "[122]\tvalidation_0-logloss:0.57663\n",
            "[123]\tvalidation_0-logloss:0.57654\n",
            "[124]\tvalidation_0-logloss:0.57643\n",
            "[125]\tvalidation_0-logloss:0.57631\n",
            "[126]\tvalidation_0-logloss:0.57621\n",
            "[127]\tvalidation_0-logloss:0.57613\n",
            "[128]\tvalidation_0-logloss:0.57603\n",
            "[129]\tvalidation_0-logloss:0.57591\n",
            "[130]\tvalidation_0-logloss:0.57579\n",
            "[131]\tvalidation_0-logloss:0.57570\n",
            "[132]\tvalidation_0-logloss:0.57562\n",
            "[133]\tvalidation_0-logloss:0.57554\n",
            "[134]\tvalidation_0-logloss:0.57545\n",
            "[135]\tvalidation_0-logloss:0.57533\n",
            "[136]\tvalidation_0-logloss:0.57525\n",
            "[137]\tvalidation_0-logloss:0.57516\n",
            "[138]\tvalidation_0-logloss:0.57509\n",
            "[139]\tvalidation_0-logloss:0.57501\n",
            "[140]\tvalidation_0-logloss:0.57489\n",
            "[141]\tvalidation_0-logloss:0.57482\n",
            "[142]\tvalidation_0-logloss:0.57473\n",
            "[143]\tvalidation_0-logloss:0.57459\n",
            "[144]\tvalidation_0-logloss:0.57447\n",
            "[145]\tvalidation_0-logloss:0.57441\n",
            "[146]\tvalidation_0-logloss:0.57433\n",
            "[147]\tvalidation_0-logloss:0.57421\n",
            "[148]\tvalidation_0-logloss:0.57414\n",
            "[149]\tvalidation_0-logloss:0.57407\n",
            "[150]\tvalidation_0-logloss:0.57396\n",
            "[151]\tvalidation_0-logloss:0.57387\n",
            "[152]\tvalidation_0-logloss:0.57375\n",
            "[153]\tvalidation_0-logloss:0.57366\n",
            "[154]\tvalidation_0-logloss:0.57359\n",
            "[155]\tvalidation_0-logloss:0.57348\n",
            "[156]\tvalidation_0-logloss:0.57343\n",
            "[157]\tvalidation_0-logloss:0.57336\n",
            "[158]\tvalidation_0-logloss:0.57327\n",
            "[159]\tvalidation_0-logloss:0.57319\n",
            "[160]\tvalidation_0-logloss:0.57311\n",
            "[161]\tvalidation_0-logloss:0.57303\n",
            "[162]\tvalidation_0-logloss:0.57295\n",
            "[163]\tvalidation_0-logloss:0.57289\n",
            "[164]\tvalidation_0-logloss:0.57284\n",
            "[165]\tvalidation_0-logloss:0.57272\n",
            "[166]\tvalidation_0-logloss:0.57268\n",
            "[167]\tvalidation_0-logloss:0.57256\n",
            "[168]\tvalidation_0-logloss:0.57252\n",
            "[169]\tvalidation_0-logloss:0.57242\n",
            "[170]\tvalidation_0-logloss:0.57231\n",
            "[171]\tvalidation_0-logloss:0.57222\n",
            "[172]\tvalidation_0-logloss:0.57216\n",
            "[173]\tvalidation_0-logloss:0.57212\n",
            "[174]\tvalidation_0-logloss:0.57205\n",
            "[175]\tvalidation_0-logloss:0.57194\n",
            "[176]\tvalidation_0-logloss:0.57188\n",
            "[177]\tvalidation_0-logloss:0.57183\n",
            "[178]\tvalidation_0-logloss:0.57172\n",
            "[179]\tvalidation_0-logloss:0.57163\n",
            "[180]\tvalidation_0-logloss:0.57157\n",
            "[181]\tvalidation_0-logloss:0.57147\n",
            "[182]\tvalidation_0-logloss:0.57139\n",
            "[183]\tvalidation_0-logloss:0.57134\n",
            "[184]\tvalidation_0-logloss:0.57128\n",
            "[185]\tvalidation_0-logloss:0.57121\n",
            "[186]\tvalidation_0-logloss:0.57111\n",
            "[187]\tvalidation_0-logloss:0.57107\n",
            "[188]\tvalidation_0-logloss:0.57097\n",
            "[189]\tvalidation_0-logloss:0.57090\n",
            "[190]\tvalidation_0-logloss:0.57087\n",
            "[191]\tvalidation_0-logloss:0.57079\n",
            "[192]\tvalidation_0-logloss:0.57075\n",
            "[193]\tvalidation_0-logloss:0.57066\n",
            "[194]\tvalidation_0-logloss:0.57061\n",
            "[195]\tvalidation_0-logloss:0.57052\n",
            "[196]\tvalidation_0-logloss:0.57049\n",
            "[197]\tvalidation_0-logloss:0.57042\n",
            "[198]\tvalidation_0-logloss:0.57035\n",
            "[199]\tvalidation_0-logloss:0.57031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:43:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (precision):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (recall):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (f1):   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [23:44:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
            "Parameters: { \"verbose\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:06 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7083, precision: 0.6962, recall: 0.0363, f1: 0.0682\n",
            "Model saved to: ~/models/xgb_classifier_2024-09-11_23-44-19.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_2yr_xgb, model_2yr_xgb = train_xgb_and_save(X_train_2yr_processed, y_train_2yr, X_test_2yr_processed, y_test_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:04 left: 00:00]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Evaluates the model with cross-validation and test set metrics.\"\"\"\n",
        "with tqdm(total=5, desc=f\"Cross-Validation\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "    cv_metrics = cross_validate(SVC(kernel = 'rbf', class_weight='balanced'), X_train_qtr_processed[:10000], y_train_qtr[:10000], cv=3, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
        "    pbar.update(5)\n",
        "\n",
        "    #print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics.mean():.4f}' for m in cv_metrics])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training knn: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:00 left: 00:00]\n",
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:12 left: 00:00]\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:12 left: 00:00]\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:12 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7477, precision: 0.4056, recall: 0.2794, f1: 0.3283\n",
            "Model saved to: ~/models/knn_2024-09-11_15-50-38.pkl\n"
          ]
        }
      ],
      "source": [
        "y_pred_qtr_knn, model_qtr_knn = train_knn_and_save(X_train_qtr_processed, y_train_qtr, X_test_qtr_processed, y_test_qtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training knn: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:00 left: 00:00]\n",
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:12 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7298, precision: 0.3303, recall: 0.2014, f1: 0.2469\n",
            "Model saved to: ~/models/knn_2024-09-11_12-31-40.pkl\n"
          ]
        }
      ],
      "source": [
        "y_pred_yr_knn, model_yr_knn = train_knn_and_save(X_train_yr_processed, y_train_yr, X_test_yr_processed, y_test_yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training knn: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:00 left: 00:00]\n",
            "Cross-Validation (accuracy): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (precision): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (recall): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (f1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:11 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7289, precision: 0.3252, recall: 0.1941, f1: 0.2402\n",
            "Model saved to: ~/models/knn_2024-09-11_12-35-40.pkl\n"
          ]
        }
      ],
      "source": [
        "y_pred_2yr_knn, model_2yr_knn = train_knn_and_save(X_train_2yr_processed, y_train_2yr, X_test_2yr_processed, y_test_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 00:04 left: 00:00]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Evaluates the model with cross-validation and test set metrics.\"\"\"\n",
        "with tqdm(total=5, desc=f\"Cross-Validation\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "    cv_metrics = cross_validate(SVC(kernel = 'rbf', class_weight='balanced'), X_train_qtr_processed[:10000], y_train_qtr[:10000], cv=3, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
        "    pbar.update(5)\n",
        "\n",
        "    #print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics.mean():.4f}' for m in cv_metrics])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fit_time': array([0.71196508, 0.65307307, 0.65739298]),\n",
              " 'score_time': array([1.00231981, 0.83814096, 0.80731201]),\n",
              " 'test_accuracy': array([0.69406119, 0.64506451, 0.67566757]),\n",
              " 'test_precision': array([0.27086495, 0.25572519, 0.26061915]),\n",
              " 'test_recall': array([0.85817308, 0.9686747 , 0.87019231]),\n",
              " 'test_f1': array([0.41176471, 0.4046301 , 0.40110803])}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.014093</td>\n",
              "      <td>0.013393</td>\n",
              "      <td>0.001951</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>0.012734</td>\n",
              "      <td>0.012177</td>\n",
              "      <td>0.014410</td>\n",
              "      <td>0.055566</td>\n",
              "      <td>0.055539</td>\n",
              "      <td>0.230144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.016781</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000582</td>\n",
              "      <td>0.000374</td>\n",
              "      <td>0.068423</td>\n",
              "      <td>0.250050</td>\n",
              "      <td>0.250823</td>\n",
              "      <td>0.250973</td>\n",
              "      <td>0.248154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.029071</td>\n",
              "      <td>0.028856</td>\n",
              "      <td>0.013157</td>\n",
              "      <td>0.042425</td>\n",
              "      <td>0.027675</td>\n",
              "      <td>0.026344</td>\n",
              "      <td>0.024527</td>\n",
              "      <td>0.033659</td>\n",
              "      <td>0.033611</td>\n",
              "      <td>0.018101</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024631</td>\n",
              "      <td>0.128452</td>\n",
              "      <td>0.010789</td>\n",
              "      <td>0.024120</td>\n",
              "      <td>0.019341</td>\n",
              "      <td>0.252471</td>\n",
              "      <td>0.433043</td>\n",
              "      <td>0.433489</td>\n",
              "      <td>0.433575</td>\n",
              "      <td>0.431943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.010949</td>\n",
              "      <td>0.010939</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.001541</td>\n",
              "      <td>0.010108</td>\n",
              "      <td>0.010104</td>\n",
              "      <td>0.009839</td>\n",
              "      <td>0.048932</td>\n",
              "      <td>0.048931</td>\n",
              "      <td>0.227502</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.011115</td>\n",
              "      <td>0.011015</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.001724</td>\n",
              "      <td>0.010202</td>\n",
              "      <td>0.010141</td>\n",
              "      <td>0.009910</td>\n",
              "      <td>0.049525</td>\n",
              "      <td>0.049520</td>\n",
              "      <td>0.227695</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.011814</td>\n",
              "      <td>0.011338</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.004523</td>\n",
              "      <td>0.010685</td>\n",
              "      <td>0.010364</td>\n",
              "      <td>0.011182</td>\n",
              "      <td>0.052031</td>\n",
              "      <td>0.052007</td>\n",
              "      <td>0.228461</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows √ó 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0              1              2              3    \\\n",
              "count  120252.000000  120252.000000  120252.000000  120252.000000   \n",
              "mean        0.014093       0.013393       0.001951       0.011064   \n",
              "std         0.029071       0.028856       0.013157       0.042425   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.010949       0.010939       0.000121       0.001541   \n",
              "50%         0.011115       0.011015       0.000281       0.001724   \n",
              "75%         0.011814       0.011338       0.000879       0.004523   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 4              5              6              7    \\\n",
              "count  120252.000000  120252.000000  120252.000000  120252.000000   \n",
              "mean        0.012734       0.012177       0.014410       0.055566   \n",
              "std         0.027675       0.026344       0.024527       0.033659   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.010108       0.010104       0.009839       0.048932   \n",
              "50%         0.010202       0.010141       0.009910       0.049525   \n",
              "75%         0.010685       0.010364       0.011182       0.052031   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 8              9    ...            111            112  \\\n",
              "count  120252.000000  120252.000000  ...  120252.000000  120252.000000   \n",
              "mean        0.055539       0.230144  ...       0.000607       0.016781   \n",
              "std         0.033611       0.018101  ...       0.024631       0.128452   \n",
              "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "25%         0.048931       0.227502  ...       0.000000       0.000000   \n",
              "50%         0.049520       0.227695  ...       0.000000       0.000000   \n",
              "75%         0.052007       0.228461  ...       0.000000       0.000000   \n",
              "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
              "\n",
              "                 113            114            115            116  \\\n",
              "count  120252.000000  120252.000000  120252.000000  120252.000000   \n",
              "mean        0.000116       0.000582       0.000374       0.068423   \n",
              "std         0.010789       0.024120       0.019341       0.252471   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 117            118            119            120  \n",
              "count  120252.000000  120252.000000  120252.000000  120252.000000  \n",
              "mean        0.250050       0.250823       0.250973       0.248154  \n",
              "std         0.433043       0.433489       0.433575       0.431943  \n",
              "min         0.000000       0.000000       0.000000       0.000000  \n",
              "25%         0.000000       0.000000       0.000000       0.000000  \n",
              "50%         0.000000       0.000000       0.000000       0.000000  \n",
              "75%         1.000000       1.000000       1.000000       0.000000  \n",
              "max         1.000000       1.000000       1.000000       1.000000  \n",
              "\n",
              "[8 rows x 121 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(X_train_qtr_processed).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation:   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "Cross-Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà [elapsed: 42:40 left: 00:00]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Evaluates the model with cross-validation and test set metrics.\"\"\"\n",
        "with tqdm(total=5, desc=f\"Cross-Validation\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "    cv_metrics = cross_validate(SVC(kernel = 'rbf'), X_train_qtr_processed, y_train_qtr, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
        "    pbar.update(5)\n",
        "\n",
        "    #print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics.mean():.4f}' for m in cv_metrics])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training svc_rbf:   0%|           [elapsed: 00:00 left: ?]"
          ]
        }
      ],
      "source": [
        "y_pred_qtr_svc, model_qtr_svc = train_svc_rbf_and_save(X_train_qtr_processed, y_train_qtr, X_test_qtr_processed, y_test_qtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_yr_svc, model_yr_svc = train_svc_rbf_and_save(X_train_yr_processed, y_train_yr, X_test_yr_processed, y_test_yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_2yr_svc, model_2yr_svc = train_svc_rbf_and_save(X_train_2yr_processed, y_train_2yr, X_test_2yr_processed, y_test_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7IFuQncCFAOI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Quarter Ahead Metrics: {'cv_accuracy': np.float64(0.5861177525890302), 'cv_precision': np.float64(0.28886531098782686), 'cv_recall': np.float64(0.3746608634582686), 'cv_f1': np.float64(0.32563369780978374), 'accuracy': 0.5739110464671209, 'precision': np.float64(0.28430531732418524), 'recall': np.float64(0.3731007315700619), 'f1': np.float64(0.32270625456315405)}\n",
            "1 Year Ahead Metrics: {'cv_accuracy': np.float64(0.5847497987573081), 'cv_precision': np.float64(0.2876763455297774), 'cv_recall': np.float64(0.37019406810692057), 'cv_f1': np.float64(0.3235231859899204), 'accuracy': 0.6013502387617322, 'precision': np.float64(0.3058765674944677), 'recall': np.float64(0.3812442537542139), 'f1': np.float64(0.33942701227830835)}\n",
            "2 Years Ahead Metrics: {'cv_accuracy': np.float64(0.5855911208007135), 'cv_precision': np.float64(0.2907180862789915), 'cv_recall': np.float64(0.378417465607723), 'cv_f1': np.float64(0.32827805522691694), 'accuracy': 0.6088211708099439, 'precision': np.float64(0.30460509390275275), 'recall': np.float64(0.3524858588865734), 'f1': np.float64(0.32680099365166987)}\n"
          ]
        }
      ],
      "source": [
        "# Step 10: Print metrics for each model\n",
        "print(\"1 Quarter Ahead Metrics:\", y_pred_qtr)\n",
        "print(\"1 Year Ahead Metrics:\", y_pred_yr)\n",
        "print(\"2 Years Ahead Metrics:\", y_pred_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Let's try a grid search - QUARTER\n",
        "best_model_qtr, best_params_qtr, best_score_qtr = run_grid_search(X_train_qtr_processed, y_train_qtr)\n",
        "\n",
        "print(f\"Best Model - QUARTER: {best_model_qtr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - QUARTER: {best_params_qtr}\")\n",
        "print(f\"Best Score - QUARTER: {best_score_qtr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "Best parameters: {'C': 0.15, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
            "Best cross-validation score: 0.3543\n",
            "Best Model - YEAR: LogisticRegression\n",
            "Best Parameters - YEAR: {'C': 0.15, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
            "Best Score - YEAR: 0.3543\n"
          ]
        }
      ],
      "source": [
        "# Let's try a grid search - YEAR\n",
        "best_model_yr, best_params_yr, best_score_yr = run_grid_search(X_train_yr_processed, y_train_yr)\n",
        "\n",
        "print(f\"Best Model - YEAR: {best_model_yr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - YEAR: {best_params_yr}\")\n",
        "print(f\"Best Score - YEAR: {best_score_yr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's try a grid search - 2 YEAR\n",
        "best_model_2yr, best_params_2yr, best_score_2yr = run_grid_search(X_train_2yr_processed, y_train_2yr)\n",
        "\n",
        "print(f\"Best Model - YEAR: {best_model_2yr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - YEAR: {best_params_2yr}\")\n",
        "print(f\"Best Score - YEAR: {best_score_2yr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "Best parameters: {'n_neighbors': 550}\n",
            "Best cross-validation score: 0.5641\n",
            "Best Model - QUARTER: KNeighborsClassifier\n",
            "Best Parameters - QUARTER: {'n_neighbors': 550}\n",
            "Best Score - QUARTER: 0.5641\n"
          ]
        }
      ],
      "source": [
        "# knn grid search\n",
        "# Let's try a grid search - QUARTER\n",
        "best_model_qtr, best_params_qtr, best_score_qtr = knn_run_grid_search(X_train_qtr_processed, y_train_qtr)\n",
        "\n",
        "print(f\"Best Model - QUARTER: {best_model_qtr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - QUARTER: {best_params_qtr}\")\n",
        "print(f\"Best Score - QUARTER: {best_score_qtr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best parameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
            "Best cross-validation score: 0.6730\n",
            "Best Model - QUARTER: XGBClassifier\n",
            "Best Parameters - QUARTER: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
            "Best Score - QUARTER: 0.6730\n"
          ]
        }
      ],
      "source": [
        "# xgboost  search\n",
        "# QUARTER\n",
        "best_model_qtr, best_params_qtr, best_score_qtr = run_xgboost(X_train_qtr_processed, y_train_qtr)\n",
        "\n",
        "print(f\"Best Model - QUARTER: {best_model_qtr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - QUARTER: {best_params_qtr}\")\n",
        "print(f\"Best Score - QUARTER: {best_score_qtr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      1.00      0.87     23202\n",
            "           1       0.70      0.03      0.06      6764\n",
            "\n",
            "    accuracy                           0.78     29966\n",
            "   macro avg       0.74      0.51      0.47     29966\n",
            "weighted avg       0.76      0.78      0.69     29966\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_model = XGBClassifier(learning_rate= 0.01, max_depth= 5, n_estimators= 200)\n",
        "best_model.fit(X_train_qtr_processed, y_train_qtr)\n",
        "predictions = best_model.predict(X_test_qtr_processed)\n",
        "\n",
        "report = classification_report(y_test_qtr, predictions)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test_qtr, predictions, labels=best_model.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=best_model.classes_)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
