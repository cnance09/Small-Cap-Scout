{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "vnTExAADftvB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxXym19bhG7A"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "KiMXAWmtprGN"
      },
      "outputs": [],
      "source": [
        "# Step 0 : filter on small caps and micro caps\n",
        "#def filter_data(df, small_cap_value=1, micro_cap_value=1):\n",
        "#    \"\"\"Filters rows based on small_cap and micro_cap values and returns a copy of the filtered DataFrame.\"\"\"\n",
        "#    filtered_df = df[(df['small_cap'] == small_cap_value) & (df['micro_cap'] == micro_cap_value)].copy()\n",
        "#    return filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "FKV_8oKrgACR"
      },
      "outputs": [],
      "source": [
        "# Step 1 : target creation + train_test_split\n",
        "# Creating target variables to automate creation of quarterly, yearly and 2-yearly targets, because well, DON'T REPEAT YOURSELF!\n",
        "def create_target_variable(df, frequency:int, threshold):\n",
        "    if frequency == 1:\n",
        "        col = 'mc_qtr_growth_pct'\n",
        "    if frequency == 4:\n",
        "        col = 'mc_yr_growth_pct'\n",
        "    if frequency == 8:\n",
        "        col = 'mc_2yr_growth_pct'\n",
        "   #else:\n",
        "   #    raise ValueError(\"Invalid frequency. Use 1 (quarterly), 4 (yearly), or 8 (2-year).\")\n",
        "    df[col] = df[col].shift(-frequency)\n",
        "    df.dropna(subset=col, inplace=True)\n",
        "    target_func = lambda x: 1 if ((x[col] > threshold) & (x.small_cap == 1)) else 0\n",
        "    df['target'] = df.apply(target_func, axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "-PdzMchGgMki"
      },
      "outputs": [],
      "source": [
        "#def drop_columns(df, cols_to_drop=None):\n",
        "#    \"\"\"Drops specified columns from the DataFrame.\"\"\"\n",
        "#\n",
        "#    if cols_to_drop is None:\n",
        "#       # Default columns to drop if none are specified\n",
        "#        cols_to_drop = ['cik', 'CIK', 'date', 'stprba', 'quarter', 'year']\n",
        "#    return df.drop(cols_to_drop, axis=1, errors='ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "71DQCJUxgOaH"
      },
      "outputs": [],
      "source": [
        "# Creating a custom function for the group split\n",
        "def group_train_test_split(data, test_size=0.2, random_state=None):\n",
        "\n",
        "    data['qtr'] = data.quarter.apply(lambda x : x.split('-')[1])\n",
        "\n",
        "\n",
        "    # We split by groups (company ticker) while keeping the data structure intact.\n",
        "    unique_groups = data['TICKER'].unique()\n",
        "    train_groups, test_groups = train_test_split(unique_groups, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Split into train and test sets\n",
        "    X_train = data[data['TICKER'].isin(train_groups)]\n",
        "    X_test = data[data['TICKER'].isin(test_groups)]\n",
        "\n",
        "    # Define columns to drop: Ticker, cik, date, quarter, year + growth columns\n",
        "    cols_to_drop = ['mc_qtr_growth', 'mc_qtr_growth_pct', 'mc_yr_growth', 'mc_yr_growth_pct', 'mc_2yr_growth', 'mc_2yr_growth_pct', 'target']\n",
        "\n",
        "    # Drop unwanted columns\n",
        "    X_train = X_train.drop(cols_to_drop + ['cik', 'CIK', 'date', 'stprba', 'quarter', 'year', 'TICKER'], axis=1, errors='ignore')\n",
        "    X_test = X_test.drop(cols_to_drop + ['cik', 'CIK', 'date', 'stprba', 'quarter', 'year', 'TICKER'], axis=1, errors='ignore')\n",
        "\n",
        "    # Extract the target variable from the dataset\n",
        "    y_train = data[data['TICKER'].isin(train_groups)]['target']\n",
        "    y_test = data[data['TICKER'].isin(test_groups)]['target']\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "wvK02xu4gT3D"
      },
      "outputs": [],
      "source": [
        "# Step 2: Identify numerical and categorical features\n",
        "def identify_feature_types(df):\n",
        "    \"\"\"Identifies the numerical and categorical columns in the DataFrame.\"\"\"\n",
        "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    # Exclude 'Ticker' from categorical features as it's not needed for transformation\n",
        "    if 'TICKER' in categorical_features:\n",
        "        categorical_features.remove('TICKER')\n",
        "\n",
        "    return numerical_features, categorical_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "1TCupWcbgUoZ"
      },
      "outputs": [],
      "source": [
        "# Step 3: Create preprocessing pipeline for numerical and categorical features\n",
        "def create_preprocessing_pipeline(numerical_features, categorical_features):\n",
        "    \"\"\"Creates the preprocessing pipeline for numerical and categorical features.\"\"\"\n",
        "    # Preprocessing for numerical data: RobustScaler to make our numbers más robusto.\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),  # Handle NaNs\n",
        "        ('scaler', RobustScaler())\n",
        "        #('scaler', MinMaxScaler()) # Scale the data\n",
        "    ])\n",
        "\n",
        "    # Preprocessing for categorical data: OneHotEncoder to give each category its own columm...\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing categories\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Encode categories\n",
        "    ])\n",
        "\n",
        "    # Combine the transformers into one big ColumnTransformer.\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_features),\n",
        "            ('cat', categorical_transformer, categorical_features)\n",
        "        ]\n",
        "    )\n",
        "    return preprocessor\n",
        "\n",
        "\n",
        "# Function to save the preprocessor\n",
        "def save_preprocessor(preprocessor, file_path='~/models/'):\n",
        "    \"\"\"Saves the preproc with a timestamp.\"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    preproc_filename = f'preprocessor_{timestamp}.pkl'\n",
        "    # Ensure model directory exists\n",
        "    if not os.path.exists(file_path):\n",
        "        os.makedirs(file_path)\n",
        "\n",
        "    file_path = os.path.join(file_path, preproc_filename   )\n",
        "    with open(file_path, 'wb') as file:\n",
        "        pickle.dump(preprocessor, file)\n",
        "\n",
        "    print(f\"Preprocessor saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "o7c2Bq-wgX2j"
      },
      "outputs": [],
      "source": [
        "# Step 4: Function to preprocess data in training mode (fitting the pipeline)\n",
        "def preprocess_training_data(X_train):\n",
        "    \"\"\"Fits and transforms the training data using the provided pipeline.\"\"\"\n",
        "    # Identify feature types\n",
        "    numerical_features, categorical_features = identify_feature_types(X_train)\n",
        "    preprocessor = create_preprocessing_pipeline(numerical_features, categorical_features)\n",
        "\n",
        "    # Fit and transform the training data\n",
        "    X_train_processed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "        # Save the preprocessor after fitting\n",
        "    save_preprocessor(preprocessor)\n",
        "\n",
        "    return X_train_processed, preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "nKfwqkKtglqk"
      },
      "outputs": [],
      "source": [
        "# Step 5: Function to preprocess new/unseen/test data in production mode (only transforming)\n",
        "def preprocess_new_data(X_new, preprocessor):\n",
        "    \"\"\"Transforms new/unseen/test data using a pre-fitted pipeline.\"\"\"\n",
        "    if preprocessor is None:\n",
        "        raise ValueError(\"The preprocessor must be fitted on training data first before transforming new data.\")\n",
        "\n",
        "    # Transform the new data (no fitting here)\n",
        "    X_new_processed = preprocessor.transform(X_new)\n",
        "    return X_new_processed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43XuFL6dg6GU"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "_avhOzqdgtaj"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_type, model_dir='~/models/'):\n",
        "    \"\"\"Saves the trained model with a timestamp.\"\"\"\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    model_filename = f'{model_type}_{timestamp}.pkl'\n",
        "\n",
        "    # Ensure model directory exists\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    # Save the trained model\n",
        "    model_path = os.path.join(model_dir, model_filename)\n",
        "    with open(model_path, 'wb') as f_model:\n",
        "        pickle.dump(model, f_model)\n",
        "\n",
        "    print(f\"Model saved to: {model_path}\")\n",
        "    return model_path\n",
        "\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test, scoring_metrics=['accuracy', 'precision', 'recall', 'f1']):\n",
        "    \"\"\"Evaluates the model with cross-validation and test set metrics.\"\"\"\n",
        "    cv_metrics = {}\n",
        "    for metric in scoring_metrics:\n",
        "        with tqdm(total=5, desc=f\"Cross-Validation ({metric})\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "            cv_metrics[metric] = cross_val_score(model, X_train, y_train, cv=5, scoring=metric)\n",
        "            pbar.update(5)\n",
        "\n",
        "    print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics[m].mean():.4f}' for m in cv_metrics])}\")\n",
        "\n",
        "    # Test on the test set\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Calculate test set metrics\n",
        "    test_metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred_test),\n",
        "        'precision': precision_score(y_test, y_pred_test),\n",
        "        'recall': recall_score(y_test, y_pred_test),\n",
        "        'f1': f1_score(y_test, y_pred_test)\n",
        "    }\n",
        "\n",
        "    # Combine cross-validated and test metrics\n",
        "    metrics = {**{f'cv_{m}': cv_metrics[m].mean() for m in cv_metrics}, **test_metrics}\n",
        "    return metrics\n",
        "\n",
        "def train_logistic_regression_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates a logistic regression model, saves the trained model, and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    model_type = 'logistic_regression'\n",
        "    model = LogisticRegression(C=0.001, max_iter=2000, solver='lbfgs')\n",
        "\n",
        "    # Train model with a progress bar\n",
        "    with tqdm(total=100, desc=f\"Training {model_type}\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "        model.fit(X_train, y_train)\n",
        "        pbar.update(100)\n",
        "\n",
        "    # Check number of iterations\n",
        "    print(f\"Number of iterations: {model.n_iter_}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(model, model_type, model_dir)\n",
        "\n",
        "    return metrics, model\n",
        "\n",
        "def train_knn_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates a K-Nearest Neighbors model, saves the trained model, and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    model_type = 'knn'\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Train model with a progress bar\n",
        "    with tqdm(total=100, desc=f\"Training {model_type}\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "        knn.fit(X_train, y_train)\n",
        "        pbar.update(100)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(knn, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(knn, model_type, model_dir)\n",
        "\n",
        "    return metrics, knn\n",
        "\n",
        "def train_svc_rbf_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates an SVM with RBF kernel, saves the trained model, and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    model_type = 'svc_rbf'\n",
        "    svc_rbf = SVC(kernel='rbf', probability=True)  # Set `probability=True` for log_loss and cross-validation\n",
        "\n",
        "    # Train model with a progress bar\n",
        "    #with tqdm(total=100, desc=f\"Training {model_type}\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "    svc_rbf.fit(X_train, y_train)\n",
        "        #pbar.update(100)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = evaluate_model(svc_rbf, X_train, y_train, X_test, y_test)\n",
        "\n",
        "    # Save the model\n",
        "    save_model(svc_rbf, model_type, model_dir)\n",
        "\n",
        "    return metrics, svc_rbf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'# Step 6: Function to train logistic regression, evaluate, and save the model\\ndef train_logistic_regression_and_save(X_train, y_train, X_test, y_test, model_dir=\\'~/models/\\'):\\n    \"\"\"Trains, evaluates a logistic regression model, saves the trained model with a timestamp and returns evaluation metrics.\"\"\"\\n\\n    # Step 1: Train logistic regression model with a progress bar\\n    logistic_model = LogisticRegression(solver=\\'saga\\', max_iter=2000)\\n    with tqdm(total=100, desc=\"Training Logistic Regression\", bar_format=\\'{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]\\') as pbar:\\n        logistic_model.fit(X_train, y_train)\\n        pbar.update(100)\\n\\n    # Check number of iterations\\n    print(f\"Number of iterations: {logistic_model.n_iter_}\")\\n\\n    # Step 2: Evaluate using cross-validation for accuracy, precision, recall, and F1-score\\n    cv_metrics = {}\\n    for metric in [\\'accuracy\\', \\'precision\\', \\'recall\\', \\'f1\\']:\\n        with tqdm(total=5, desc=f\"Cross-Validation ({metric})\", bar_format=\\'{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]\\') as pbar:\\n            cv_metrics[metric] = cross_val_score(logistic_model, X_train, y_train, cv=5, scoring=metric)\\n            pbar.update(5)\\n\\n    print(f\"Cross-validated Metrics: {\\', \\'.join([f\\'{m}: {cv_metrics[m].mean():.4f}\\' for m in cv_metrics])}\")\\n\\n    # Step 3: Test on the test set\\n    y_pred_test = logistic_model.predict(X_test)\\n\\n    # Calculate test set metrics\\n    test_metrics = {\\n        \\'accuracy\\': accuracy_score(y_test, y_pred_test),\\n        \\'precision\\': precision_score(y_test, y_pred_test),\\n        \\'recall\\': recall_score(y_test, y_pred_test),\\n        \\'f1\\': f1_score(y_test, y_pred_test)\\n    }\\n\\n    # Combine cross-validated and test metrics into a single dictionary\\n    metrics = {**{f\\'cv_{m}\\': cv_metrics[m].mean() for m in cv_metrics}, **test_metrics}\\n\\n    # Step 4: Save the model with timestamp and type\\n    timestamp = datetime.now().strftime(\\'%Y-%m-%d_%H-%M-%S\\')\\n    model_filename = f\\'logistic_regression_{timestamp}.pkl\\'\\n\\n    # Ensure model directory exists\\n    if not os.path.exists(model_dir):\\n        os.makedirs(model_dir)\\n\\n    # Save the trained model\\n    model_path = os.path.join(model_dir, model_filename)\\n    with open(model_path, \\'wb\\') as f_model:\\n        pickle.dump(logistic_model, f_model)\\n\\n    print(f\"Model saved to: {model_path}\")\\n\\n    return metrics, logistic_model'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''# Step 6: Function to train logistic regression, evaluate, and save the model\n",
        "def train_logistic_regression_and_save(X_train, y_train, X_test, y_test, model_dir='~/models/'):\n",
        "    \"\"\"Trains, evaluates a logistic regression model, saves the trained model with a timestamp and returns evaluation metrics.\"\"\"\n",
        "\n",
        "    # Step 1: Train logistic regression model with a progress bar\n",
        "    logistic_model = LogisticRegression(solver='saga', max_iter=2000)\n",
        "    with tqdm(total=100, desc=\"Training Logistic Regression\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "        logistic_model.fit(X_train, y_train)\n",
        "        pbar.update(100)\n",
        "\n",
        "    # Check number of iterations\n",
        "    print(f\"Number of iterations: {logistic_model.n_iter_}\")\n",
        "\n",
        "    # Step 2: Evaluate using cross-validation for accuracy, precision, recall, and F1-score\n",
        "    cv_metrics = {}\n",
        "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
        "        with tqdm(total=5, desc=f\"Cross-Validation ({metric})\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "            cv_metrics[metric] = cross_val_score(logistic_model, X_train, y_train, cv=5, scoring=metric)\n",
        "            pbar.update(5)\n",
        "\n",
        "    print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics[m].mean():.4f}' for m in cv_metrics])}\")\n",
        "\n",
        "    # Step 3: Test on the test set\n",
        "    y_pred_test = logistic_model.predict(X_test)\n",
        "\n",
        "    # Calculate test set metrics\n",
        "    test_metrics = {\n",
        "        'accuracy': accuracy_score(y_test, y_pred_test),\n",
        "        'precision': precision_score(y_test, y_pred_test),\n",
        "        'recall': recall_score(y_test, y_pred_test),\n",
        "        'f1': f1_score(y_test, y_pred_test)\n",
        "    }\n",
        "\n",
        "    # Combine cross-validated and test metrics into a single dictionary\n",
        "    metrics = {**{f'cv_{m}': cv_metrics[m].mean() for m in cv_metrics}, **test_metrics}\n",
        "\n",
        "    # Step 4: Save the model with timestamp and type\n",
        "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "    model_filename = f'logistic_regression_{timestamp}.pkl'\n",
        "\n",
        "    # Ensure model directory exists\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    # Save the trained model\n",
        "    model_path = os.path.join(model_dir, model_filename)\n",
        "    with open(model_path, 'wb') as f_model:\n",
        "        pickle.dump(logistic_model, f_model)\n",
        "\n",
        "    print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "    return metrics, logistic_model'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_grid_search(X_train, y_train):\n",
        "    \"\"\"Runs a grid search on logistic regression model to find the best hyperparameters.\"\"\"\n",
        "\n",
        "    # Define the parameter grid for Logistic Regression\n",
        "    param_grid = {\n",
        "        'solver': ['saga', 'lbfgs'],  # Different solvers\n",
        "        'max_iter': [1500, 2000, 2500],  # Number of iterations\n",
        "        'C': [0.005, 0.007, 0.01, 0.12, 0.15]  # Regularization strength\n",
        "    }\n",
        "\n",
        "    # Create a Logistic Regression model\n",
        "    logistic_model = LogisticRegression()\n",
        "\n",
        "    # Set up the GridSearchCV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=logistic_model,\n",
        "        param_grid=param_grid,\n",
        "        scoring='precision',  # Choose appropriate scoring metric\n",
        "        cv=5,  # Number of cross-validation folds\n",
        "        n_jobs=-1,  # Use all available cores\n",
        "        verbose=1  # Verbosity level\n",
        "    )\n",
        "\n",
        "    # Fit Grid Search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "    print(f\"Best cross-validation score: {best_score:.4f}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    return best_model, best_params, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "def knn_run_grid_search(X_train, y_train):\n",
        "    \"\"\"Runs a grid search on knn model to find the best hyperparameters.\"\"\"\n",
        "\n",
        "    # Define the parameter grid for Logistic Regression\n",
        "    param_grid = {\n",
        "        'n_neighbors': [550],  # Different solvers\n",
        "        #'max_iter': [1500, 2000, 2500],  # Number of iterations\n",
        "        #'C': [0.005, 0.007, 0.01, 0.12, 0.15]  # Regularization strength\n",
        "    }\n",
        "\n",
        "    # Create a Logistic Regression model\n",
        "    knn_model = KNeighborsClassifier()\n",
        "\n",
        "    # Set up the GridSearchCV\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=knn_model,\n",
        "        param_grid=param_grid,\n",
        "        scoring='precision',  # Choose appropriate scoring metric\n",
        "        cv=3,  # Number of cross-validation folds\n",
        "        n_jobs=-1,  # Use all available cores\n",
        "        verbose=1  # Verbosity level\n",
        "    )\n",
        "\n",
        "    # Fit Grid Search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "    print(f\"Best cross-validation score: {best_score:.4f}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    return best_model, best_params, best_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_xgboost(X_train, y_train):\n",
        "    \"\"\"Runs a grid search on knn model to find the best hyperparameters.\"\"\"\n",
        "\n",
        "    # Define the parameter grid for Logistic Regression\n",
        "    param_grid = param_grid = {'n_estimators': [200],\n",
        "                               'learning_rate': [0.01],\n",
        "                               'max_depth': [5]}\n",
        "\n",
        "#{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
        "\n",
        "    # Create a Logistic Regression model\n",
        "    model = XGBClassifier()\n",
        "\n",
        "    # Set up the search\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grid,\n",
        "        scoring='precision',  # Choose appropriate scoring metric\n",
        "        cv=3,  # Number of cross-validation folds\n",
        "        n_jobs=-1,  # Use all available cores\n",
        "        verbose=1  # Verbosity level\n",
        "    )\n",
        "\n",
        "    # Fit Grid Search\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "    print(f\"Best cross-validation score: {best_score:.4f}\")\n",
        "\n",
        "    # Get the best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    return best_model, best_params, best_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnR372rBhduh"
      },
      "source": [
        "# **Running the functions on the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_7Ktzy3hj9u",
        "outputId": "00c8bbe3-1775-467b-ba43-4039b75fd042"
      },
      "outputs": [],
      "source": [
        "\n",
        "# preprocessor import create_target_variable, group_train_test_split, identify_feature_types, create_preprocessing_pipeline,preprocess_training_data, preprocess_new_data,train_logistic_regression, filter_data\n",
        "\n",
        "\n",
        "df = pd.read_csv('~/Small-Cap-Scout/raw_data/data_for_preprocessing.csv', index_col=[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "hl1aO3mihsKZ",
        "outputId": "9d7e5310-9db6-4671-9172-4bd86b40c8f9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cik</th>\n",
              "      <th>date</th>\n",
              "      <th>Assets</th>\n",
              "      <th>AssetsCurrent</th>\n",
              "      <th>Cash</th>\n",
              "      <th>AssetsNoncurrent</th>\n",
              "      <th>Liabilities</th>\n",
              "      <th>LiabilitiesCurrent</th>\n",
              "      <th>LiabilitiesNoncurrent</th>\n",
              "      <th>Equity</th>\n",
              "      <th>...</th>\n",
              "      <th>TICKER</th>\n",
              "      <th>market_cap</th>\n",
              "      <th>mc_qtr_growth</th>\n",
              "      <th>mc_qtr_growth_pct</th>\n",
              "      <th>mc_yr_growth</th>\n",
              "      <th>mc_yr_growth_pct</th>\n",
              "      <th>mc_2yr_growth</th>\n",
              "      <th>mc_2yr_growth_pct</th>\n",
              "      <th>small_cap</th>\n",
              "      <th>micro_cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011-02-28</td>\n",
              "      <td>1.655991e+09</td>\n",
              "      <td>9.278390e+08</td>\n",
              "      <td>54716000.0</td>\n",
              "      <td>409295000.0</td>\n",
              "      <td>8.513950e+08</td>\n",
              "      <td>419182000.0</td>\n",
              "      <td>432213000.0</td>\n",
              "      <td>804596000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>1045.889727</td>\n",
              "      <td>46.783392</td>\n",
              "      <td>0.046825</td>\n",
              "      <td>77.281557</td>\n",
              "      <td>0.079786</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011-05-31</td>\n",
              "      <td>1.703727e+09</td>\n",
              "      <td>9.139850e+08</td>\n",
              "      <td>57433000.0</td>\n",
              "      <td>465365000.0</td>\n",
              "      <td>8.684380e+08</td>\n",
              "      <td>416010000.0</td>\n",
              "      <td>452428000.0</td>\n",
              "      <td>835289000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>1024.472219</td>\n",
              "      <td>-21.417508</td>\n",
              "      <td>-0.020478</td>\n",
              "      <td>306.796787</td>\n",
              "      <td>0.427487</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011-08-31</td>\n",
              "      <td>1.752372e+09</td>\n",
              "      <td>9.442470e+08</td>\n",
              "      <td>35523000.0</td>\n",
              "      <td>472856000.0</td>\n",
              "      <td>9.032430e+08</td>\n",
              "      <td>350085000.0</td>\n",
              "      <td>553158000.0</td>\n",
              "      <td>849129000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>882.619592</td>\n",
              "      <td>-141.852627</td>\n",
              "      <td>-0.138464</td>\n",
              "      <td>255.395538</td>\n",
              "      <td>0.407184</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1750</td>\n",
              "      <td>2011-11-30</td>\n",
              "      <td>1.821612e+09</td>\n",
              "      <td>9.550530e+08</td>\n",
              "      <td>27870000.0</td>\n",
              "      <td>521431000.0</td>\n",
              "      <td>9.582200e+08</td>\n",
              "      <td>374944000.0</td>\n",
              "      <td>583276000.0</td>\n",
              "      <td>863392000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>727.886752</td>\n",
              "      <td>-154.732840</td>\n",
              "      <td>-0.175311</td>\n",
              "      <td>-271.219583</td>\n",
              "      <td>-0.271462</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1750</td>\n",
              "      <td>2012-02-29</td>\n",
              "      <td>2.220293e+09</td>\n",
              "      <td>1.065389e+09</td>\n",
              "      <td>59294000.0</td>\n",
              "      <td>797765000.0</td>\n",
              "      <td>1.328974e+09</td>\n",
              "      <td>560986000.0</td>\n",
              "      <td>767988000.0</td>\n",
              "      <td>891319000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>AIR</td>\n",
              "      <td>899.522315</td>\n",
              "      <td>171.635564</td>\n",
              "      <td>0.235800</td>\n",
              "      <td>-146.367411</td>\n",
              "      <td>-0.139945</td>\n",
              "      <td>-69.085854</td>\n",
              "      <td>-0.071325</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 59 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    cik        date        Assets  AssetsCurrent        Cash  \\\n",
              "0  1750  2011-02-28  1.655991e+09   9.278390e+08  54716000.0   \n",
              "1  1750  2011-05-31  1.703727e+09   9.139850e+08  57433000.0   \n",
              "2  1750  2011-08-31  1.752372e+09   9.442470e+08  35523000.0   \n",
              "3  1750  2011-11-30  1.821612e+09   9.550530e+08  27870000.0   \n",
              "4  1750  2012-02-29  2.220293e+09   1.065389e+09  59294000.0   \n",
              "\n",
              "   AssetsNoncurrent   Liabilities  LiabilitiesCurrent  LiabilitiesNoncurrent  \\\n",
              "0       409295000.0  8.513950e+08         419182000.0            432213000.0   \n",
              "1       465365000.0  8.684380e+08         416010000.0            452428000.0   \n",
              "2       472856000.0  9.032430e+08         350085000.0            553158000.0   \n",
              "3       521431000.0  9.582200e+08         374944000.0            583276000.0   \n",
              "4       797765000.0  1.328974e+09         560986000.0            767988000.0   \n",
              "\n",
              "        Equity  ...  TICKER   market_cap  mc_qtr_growth  mc_qtr_growth_pct  \\\n",
              "0  804596000.0  ...     AIR  1045.889727      46.783392           0.046825   \n",
              "1  835289000.0  ...     AIR  1024.472219     -21.417508          -0.020478   \n",
              "2  849129000.0  ...     AIR   882.619592    -141.852627          -0.138464   \n",
              "3  863392000.0  ...     AIR   727.886752    -154.732840          -0.175311   \n",
              "4  891319000.0  ...     AIR   899.522315     171.635564           0.235800   \n",
              "\n",
              "   mc_yr_growth  mc_yr_growth_pct  mc_2yr_growth  mc_2yr_growth_pct  \\\n",
              "0     77.281557          0.079786            NaN                NaN   \n",
              "1    306.796787          0.427487            NaN                NaN   \n",
              "2    255.395538          0.407184            NaN                NaN   \n",
              "3   -271.219583         -0.271462            NaN                NaN   \n",
              "4   -146.367411         -0.139945     -69.085854          -0.071325   \n",
              "\n",
              "   small_cap  micro_cap  \n",
              "0          1          0  \n",
              "1          1          0  \n",
              "2          1          0  \n",
              "3          1          0  \n",
              "4          1          0  \n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ren7WhjaxXoH",
        "outputId": "4c2c7da9-4af8-4fe0-ee78-44d18e9f5224"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['cik', 'date', 'Assets', 'AssetsCurrent', 'Cash', 'AssetsNoncurrent',\n",
              "       'Liabilities', 'LiabilitiesCurrent', 'LiabilitiesNoncurrent', 'Equity',\n",
              "       'HolderEquity', 'RetainedEarnings', 'AdditionalPaidInCapital',\n",
              "       'TreasuryStockValue', 'TemporaryEquity', 'RedeemableEquity',\n",
              "       'LiabilitiesAndEquity', 'Revenues', 'CostOfRevenue', 'GrossProfit',\n",
              "       'OperatingExpenses', 'OperatingIncomeLoss',\n",
              "       'IncomeLossFromContinuingOperationsBeforeIncomeTaxExpenseBenefit',\n",
              "       'AllIncomeTaxExpenseBenefit', 'IncomeLossFromContinuingOperations',\n",
              "       'IncomeLossFromDiscontinuedOperationsNetOfTax', 'ProfitLoss',\n",
              "       'NetIncomeLossAttributableToNoncontrollingInterest', 'NetIncomeLoss',\n",
              "       'NetCashProvidedByUsedInOperatingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInFinancingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInInvestingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInOperatingActivities',\n",
              "       'NetCashProvidedByUsedInFinancingActivities',\n",
              "       'NetCashProvidedByUsedInInvestingActivities',\n",
              "       'CashProvidedByUsedInOperatingActivitiesDiscontinuedOperations',\n",
              "       'CashProvidedByUsedInInvestingActivitiesDiscontinuedOperations',\n",
              "       'CashProvidedByUsedInFinancingActivitiesDiscontinuedOperations',\n",
              "       'EffectOfExchangeRateFinal',\n",
              "       'CashPeriodIncreaseDecreaseIncludingExRateEffectFinal', 'afs', 'sic_2d',\n",
              "       'quarter', 'year', 'GDP', 'interest_rate', 'unemployment_rate',\n",
              "       'median_cpi', 'CIK', 'TICKER', 'market_cap', 'mc_qtr_growth',\n",
              "       'mc_qtr_growth_pct', 'mc_yr_growth', 'mc_yr_growth_pct',\n",
              "       'mc_2yr_growth', 'mc_2yr_growth_pct', 'small_cap', 'micro_cap'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "c1P5otIWl2Dl"
      },
      "outputs": [],
      "source": [
        "# Step 2: Drop unwanted columns before target creation\n",
        "#df_cleaned = drop_columns(df, cols_to_drop=['cik', 'CIK', 'date', 'stprba', 'quarter', 'year', ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_cleaned.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "fqikqbbIl-TV"
      },
      "outputs": [],
      "source": [
        "# Step 3: Create target variables and split the data\n",
        "df_qtr = create_target_variable(df, frequency=1, threshold=0.5)\n",
        "df_yr = create_target_variable(df, frequency=4, threshold=0.5)\n",
        "df_2yr = create_target_variable(df, frequency=8, threshold=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "s22arfsqmA2H"
      },
      "outputs": [],
      "source": [
        "X_train_qtr, X_test_qtr, y_train_qtr, y_test_qtr = group_train_test_split(df_qtr)\n",
        "X_train_yr, X_test_yr, y_train_yr, y_test_yr = group_train_test_split(df_yr)\n",
        "X_train_2yr, X_test_2yr, y_train_2yr, y_test_2yr = group_train_test_split(df_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Assets', 'AssetsCurrent', 'Cash', 'AssetsNoncurrent', 'Liabilities',\n",
              "       'LiabilitiesCurrent', 'LiabilitiesNoncurrent', 'Equity', 'HolderEquity',\n",
              "       'RetainedEarnings', 'AdditionalPaidInCapital', 'TreasuryStockValue',\n",
              "       'TemporaryEquity', 'RedeemableEquity', 'LiabilitiesAndEquity',\n",
              "       'Revenues', 'CostOfRevenue', 'GrossProfit', 'OperatingExpenses',\n",
              "       'OperatingIncomeLoss',\n",
              "       'IncomeLossFromContinuingOperationsBeforeIncomeTaxExpenseBenefit',\n",
              "       'AllIncomeTaxExpenseBenefit', 'IncomeLossFromContinuingOperations',\n",
              "       'IncomeLossFromDiscontinuedOperationsNetOfTax', 'ProfitLoss',\n",
              "       'NetIncomeLossAttributableToNoncontrollingInterest', 'NetIncomeLoss',\n",
              "       'NetCashProvidedByUsedInOperatingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInFinancingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInInvestingActivitiesContinuingOperations',\n",
              "       'NetCashProvidedByUsedInOperatingActivities',\n",
              "       'NetCashProvidedByUsedInFinancingActivities',\n",
              "       'NetCashProvidedByUsedInInvestingActivities',\n",
              "       'CashProvidedByUsedInOperatingActivitiesDiscontinuedOperations',\n",
              "       'CashProvidedByUsedInInvestingActivitiesDiscontinuedOperations',\n",
              "       'CashProvidedByUsedInFinancingActivitiesDiscontinuedOperations',\n",
              "       'EffectOfExchangeRateFinal',\n",
              "       'CashPeriodIncreaseDecreaseIncludingExRateEffectFinal', 'afs', 'sic_2d',\n",
              "       'GDP', 'interest_rate', 'unemployment_rate', 'median_cpi', 'market_cap',\n",
              "       'small_cap', 'micro_cap', 'qtr'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_qtr.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "VxzH3rREuc4t"
      },
      "outputs": [],
      "source": [
        "# Step 4:  Identify feature types after splitting\n",
        "#numerical_features_qtr, categorical_features_qtr = identify_feature_types(X_train_qtr)\n",
        "#numerical_features_yr, categorical_features_yr = identify_feature_types(X_train_yr)\n",
        "#numerical_features_2yr, categorical_features_2yr = identify_feature_types(X_train_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "abVrvnn6ztXY"
      },
      "outputs": [],
      "source": [
        "# Step 5: Create the preprocessing pipeline\n",
        "#preprocessor_qtr = create_preprocessing_pipeline(numerical_features_qtr, categorical_features_qtr)\n",
        "#preprocessor_yr = create_preprocessing_pipeline(numerical_features_yr, categorical_features_yr)\n",
        "#preprocessor_2yr = create_preprocessing_pipeline(numerical_features_2yr, categorical_features_2yr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ChuCubny0QXz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessor saved to ~/models/preprocessor_2024-09-11_16-09-45.pkl\n",
            "Preprocessor saved to ~/models/preprocessor_2024-09-11_16-09-46.pkl\n",
            "Preprocessor saved to ~/models/preprocessor_2024-09-11_16-09-47.pkl\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Preprocess the training data\n",
        "X_train_qtr_processed, preprocessor_qtr = preprocess_training_data(X_train_qtr)\n",
        "X_train_yr_processed, preprocessor_yr = preprocess_training_data(X_train_yr)\n",
        "X_train_2yr_processed, preprocessor_2yr = preprocess_training_data(X_train_2yr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.587806</td>\n",
              "      <td>6.206001</td>\n",
              "      <td>2.433626</td>\n",
              "      <td>3.077850</td>\n",
              "      <td>4.502328</td>\n",
              "      <td>8.117856</td>\n",
              "      <td>3.190771</td>\n",
              "      <td>2.032721</td>\n",
              "      <td>2.040982</td>\n",
              "      <td>2.614222</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.014243</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>0.068833</td>\n",
              "      <td>0.250096</td>\n",
              "      <td>0.250772</td>\n",
              "      <td>0.250939</td>\n",
              "      <td>0.248193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>33.547617</td>\n",
              "      <td>72.119492</td>\n",
              "      <td>21.175265</td>\n",
              "      <td>15.030584</td>\n",
              "      <td>47.086562</td>\n",
              "      <td>99.850012</td>\n",
              "      <td>17.558954</td>\n",
              "      <td>11.147951</td>\n",
              "      <td>11.215548</td>\n",
              "      <td>18.968194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009583</td>\n",
              "      <td>0.118490</td>\n",
              "      <td>0.014154</td>\n",
              "      <td>0.024167</td>\n",
              "      <td>0.012921</td>\n",
              "      <td>0.253172</td>\n",
              "      <td>0.433070</td>\n",
              "      <td>0.433459</td>\n",
              "      <td>0.433555</td>\n",
              "      <td>0.431966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-12.809220</td>\n",
              "      <td>-27.529044</td>\n",
              "      <td>-0.367373</td>\n",
              "      <td>-0.063492</td>\n",
              "      <td>-17.414588</td>\n",
              "      <td>-38.595290</td>\n",
              "      <td>-6.929684</td>\n",
              "      <td>-15.657174</td>\n",
              "      <td>-15.768628</td>\n",
              "      <td>-223.352056</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.196516</td>\n",
              "      <td>-0.195548</td>\n",
              "      <td>-0.210598</td>\n",
              "      <td>-0.059349</td>\n",
              "      <td>-0.165853</td>\n",
              "      <td>-0.142591</td>\n",
              "      <td>-0.054015</td>\n",
              "      <td>-0.192495</td>\n",
              "      <td>-0.192308</td>\n",
              "      <td>-0.190327</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.803484</td>\n",
              "      <td>0.804452</td>\n",
              "      <td>0.789402</td>\n",
              "      <td>0.940651</td>\n",
              "      <td>0.834147</td>\n",
              "      <td>0.857409</td>\n",
              "      <td>0.945985</td>\n",
              "      <td>0.807505</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.809673</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1139.129139</td>\n",
              "      <td>2471.175724</td>\n",
              "      <td>1280.480462</td>\n",
              "      <td>502.786826</td>\n",
              "      <td>1689.098060</td>\n",
              "      <td>3766.968713</td>\n",
              "      <td>691.843966</td>\n",
              "      <td>300.366281</td>\n",
              "      <td>302.548017</td>\n",
              "      <td>757.562296</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0              1              2              3    \\\n",
              "count  119782.000000  119782.000000  119782.000000  119782.000000   \n",
              "mean        3.587806       6.206001       2.433626       3.077850   \n",
              "std        33.547617      72.119492      21.175265      15.030584   \n",
              "min       -12.809220     -27.529044      -0.367373      -0.063492   \n",
              "25%        -0.196516      -0.195548      -0.210598      -0.059349   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.803484       0.804452       0.789402       0.940651   \n",
              "max      1139.129139    2471.175724    1280.480462     502.786826   \n",
              "\n",
              "                 4              5              6              7    \\\n",
              "count  119782.000000  119782.000000  119782.000000  119782.000000   \n",
              "mean        4.502328       8.117856       3.190771       2.032721   \n",
              "std        47.086562      99.850012      17.558954      11.147951   \n",
              "min       -17.414588     -38.595290      -6.929684     -15.657174   \n",
              "25%        -0.165853      -0.142591      -0.054015      -0.192495   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.834147       0.857409       0.945985       0.807505   \n",
              "max      1689.098060    3766.968713     691.843966     300.366281   \n",
              "\n",
              "                 8              9    ...            111            112  \\\n",
              "count  119782.000000  119782.000000  ...  119782.000000  119782.000000   \n",
              "mean        2.040982       2.614222  ...       0.000092       0.014243   \n",
              "std        11.215548      18.968194  ...       0.009583       0.118490   \n",
              "min       -15.768628    -223.352056  ...       0.000000       0.000000   \n",
              "25%        -0.192308      -0.190327  ...       0.000000       0.000000   \n",
              "50%         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "75%         0.807692       0.809673  ...       0.000000       0.000000   \n",
              "max       302.548017     757.562296  ...       1.000000       1.000000   \n",
              "\n",
              "                 113            114            115            116  \\\n",
              "count  119782.000000  119782.000000  119782.000000  119782.000000   \n",
              "mean        0.000200       0.000584       0.000167       0.068833   \n",
              "std         0.014154       0.024167       0.012921       0.253172   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 117            118            119            120  \n",
              "count  119782.000000  119782.000000  119782.000000  119782.000000  \n",
              "mean        0.250096       0.250772       0.250939       0.248193  \n",
              "std         0.433070       0.433459       0.433555       0.431966  \n",
              "min         0.000000       0.000000       0.000000       0.000000  \n",
              "25%         0.000000       0.000000       0.000000       0.000000  \n",
              "50%         0.000000       0.000000       0.000000       0.000000  \n",
              "75%         1.000000       1.000000       1.000000       0.000000  \n",
              "max         1.000000       1.000000       1.000000       1.000000  \n",
              "\n",
              "[8 rows x 121 columns]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(X_train_qtr_processed).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Assets</th>\n",
              "      <th>AssetsCurrent</th>\n",
              "      <th>Cash</th>\n",
              "      <th>AssetsNoncurrent</th>\n",
              "      <th>Liabilities</th>\n",
              "      <th>LiabilitiesCurrent</th>\n",
              "      <th>LiabilitiesNoncurrent</th>\n",
              "      <th>Equity</th>\n",
              "      <th>HolderEquity</th>\n",
              "      <th>RetainedEarnings</th>\n",
              "      <th>...</th>\n",
              "      <th>CashProvidedByUsedInFinancingActivitiesDiscontinuedOperations</th>\n",
              "      <th>EffectOfExchangeRateFinal</th>\n",
              "      <th>CashPeriodIncreaseDecreaseIncludingExRateEffectFinal</th>\n",
              "      <th>GDP</th>\n",
              "      <th>interest_rate</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>median_cpi</th>\n",
              "      <th>market_cap</th>\n",
              "      <th>small_cap</th>\n",
              "      <th>micro_cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>1.197820e+05</td>\n",
              "      <td>119782.000000</td>\n",
              "      <td>119782.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.447424e+10</td>\n",
              "      <td>1.126453e+10</td>\n",
              "      <td>6.308346e+08</td>\n",
              "      <td>3.131615e+09</td>\n",
              "      <td>1.179153e+10</td>\n",
              "      <td>9.349043e+09</td>\n",
              "      <td>2.399988e+09</td>\n",
              "      <td>2.637937e+09</td>\n",
              "      <td>2.627883e+09</td>\n",
              "      <td>1.586650e+09</td>\n",
              "      <td>...</td>\n",
              "      <td>4.410844e+04</td>\n",
              "      <td>-3.048736e+06</td>\n",
              "      <td>5.043658e+07</td>\n",
              "      <td>2.478345</td>\n",
              "      <td>0.978266</td>\n",
              "      <td>5.467949</td>\n",
              "      <td>2.777707</td>\n",
              "      <td>7.455004e+03</td>\n",
              "      <td>0.679752</td>\n",
              "      <td>0.398992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.274765e+11</td>\n",
              "      <td>1.263384e+11</td>\n",
              "      <td>4.976753e+09</td>\n",
              "      <td>1.500265e+10</td>\n",
              "      <td>1.186213e+11</td>\n",
              "      <td>1.127988e+11</td>\n",
              "      <td>1.298469e+10</td>\n",
              "      <td>1.305303e+10</td>\n",
              "      <td>1.303758e+10</td>\n",
              "      <td>1.136513e+10</td>\n",
              "      <td>...</td>\n",
              "      <td>4.800056e+07</td>\n",
              "      <td>1.517667e+08</td>\n",
              "      <td>2.748069e+09</td>\n",
              "      <td>8.919305</td>\n",
              "      <td>1.354245</td>\n",
              "      <td>1.837626</td>\n",
              "      <td>1.329234</td>\n",
              "      <td>4.203100e+04</td>\n",
              "      <td>0.466574</td>\n",
              "      <td>0.489693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-4.783227e+10</td>\n",
              "      <td>-4.783227e+10</td>\n",
              "      <td>-2.747500e+07</td>\n",
              "      <td>-3.889437e+06</td>\n",
              "      <td>-4.342195e+10</td>\n",
              "      <td>-4.342195e+10</td>\n",
              "      <td>-5.084000e+09</td>\n",
              "      <td>-1.807500e+10</td>\n",
              "      <td>-1.807500e+10</td>\n",
              "      <td>-1.338050e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.140119e+09</td>\n",
              "      <td>-3.234200e+10</td>\n",
              "      <td>-1.736000e+11</td>\n",
              "      <td>-69.630993</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>-0.286064</td>\n",
              "      <td>5.317758e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.432575e+07</td>\n",
              "      <td>5.034100e+07</td>\n",
              "      <td>9.371272e+06</td>\n",
              "      <td>2.460138e+05</td>\n",
              "      <td>3.136575e+07</td>\n",
              "      <td>1.736563e+07</td>\n",
              "      <td>4.970000e+05</td>\n",
              "      <td>3.245181e+07</td>\n",
              "      <td>3.178254e+07</td>\n",
              "      <td>-9.374500e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+03</td>\n",
              "      <td>-1.385979e+07</td>\n",
              "      <td>1.388811</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>1.961900</td>\n",
              "      <td>8.357113e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>8.410590e+08</td>\n",
              "      <td>3.929010e+08</td>\n",
              "      <td>5.886750e+07</td>\n",
              "      <td>5.948477e+07</td>\n",
              "      <td>4.491860e+08</td>\n",
              "      <td>1.784480e+08</td>\n",
              "      <td>4.044050e+07</td>\n",
              "      <td>2.578430e+08</td>\n",
              "      <td>2.553315e+08</td>\n",
              "      <td>2.029300e+07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-4.014000e+03</td>\n",
              "      <td>2.590671</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.452308</td>\n",
              "      <td>6.248520e+02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.894192e+09</td>\n",
              "      <td>1.802134e+09</td>\n",
              "      <td>2.443980e+08</td>\n",
              "      <td>9.983878e+08</td>\n",
              "      <td>2.550584e+09</td>\n",
              "      <td>1.147048e+09</td>\n",
              "      <td>7.399882e+08</td>\n",
              "      <td>1.203343e+09</td>\n",
              "      <td>1.194238e+09</td>\n",
              "      <td>5.054225e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.581288e+07</td>\n",
              "      <td>4.056326</td>\n",
              "      <td>1.510000</td>\n",
              "      <td>6.700000</td>\n",
              "      <td>2.966116</td>\n",
              "      <td>3.175987e+03</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.329380e+12</td>\n",
              "      <td>4.329380e+12</td>\n",
              "      <td>3.010060e+11</td>\n",
              "      <td>5.019120e+11</td>\n",
              "      <td>4.255655e+12</td>\n",
              "      <td>4.255655e+12</td>\n",
              "      <td>5.116530e+11</td>\n",
              "      <td>3.519540e+11</td>\n",
              "      <td>3.519540e+11</td>\n",
              "      <td>4.539270e+11</td>\n",
              "      <td>...</td>\n",
              "      <td>1.199100e+10</td>\n",
              "      <td>9.155000e+09</td>\n",
              "      <td>2.639780e+11</td>\n",
              "      <td>45.706033</td>\n",
              "      <td>5.330000</td>\n",
              "      <td>14.700000</td>\n",
              "      <td>8.048036</td>\n",
              "      <td>2.974308e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Assets  AssetsCurrent          Cash  AssetsNoncurrent  \\\n",
              "count  1.197820e+05   1.197820e+05  1.197820e+05      1.197820e+05   \n",
              "mean   1.447424e+10   1.126453e+10  6.308346e+08      3.131615e+09   \n",
              "std    1.274765e+11   1.263384e+11  4.976753e+09      1.500265e+10   \n",
              "min   -4.783227e+10  -4.783227e+10 -2.747500e+07     -3.889437e+06   \n",
              "25%    9.432575e+07   5.034100e+07  9.371272e+06      2.460138e+05   \n",
              "50%    8.410590e+08   3.929010e+08  5.886750e+07      5.948477e+07   \n",
              "75%    3.894192e+09   1.802134e+09  2.443980e+08      9.983878e+08   \n",
              "max    4.329380e+12   4.329380e+12  3.010060e+11      5.019120e+11   \n",
              "\n",
              "        Liabilities  LiabilitiesCurrent  LiabilitiesNoncurrent        Equity  \\\n",
              "count  1.197820e+05        1.197820e+05           1.197820e+05  1.197820e+05   \n",
              "mean   1.179153e+10        9.349043e+09           2.399988e+09  2.637937e+09   \n",
              "std    1.186213e+11        1.127988e+11           1.298469e+10  1.305303e+10   \n",
              "min   -4.342195e+10       -4.342195e+10          -5.084000e+09 -1.807500e+10   \n",
              "25%    3.136575e+07        1.736563e+07           4.970000e+05  3.245181e+07   \n",
              "50%    4.491860e+08        1.784480e+08           4.044050e+07  2.578430e+08   \n",
              "75%    2.550584e+09        1.147048e+09           7.399882e+08  1.203343e+09   \n",
              "max    4.255655e+12        4.255655e+12           5.116530e+11  3.519540e+11   \n",
              "\n",
              "       HolderEquity  RetainedEarnings  ...  \\\n",
              "count  1.197820e+05      1.197820e+05  ...   \n",
              "mean   2.627883e+09      1.586650e+09  ...   \n",
              "std    1.303758e+10      1.136513e+10  ...   \n",
              "min   -1.807500e+10     -1.338050e+11  ...   \n",
              "25%    3.178254e+07     -9.374500e+07  ...   \n",
              "50%    2.553315e+08      2.029300e+07  ...   \n",
              "75%    1.194238e+09      5.054225e+08  ...   \n",
              "max    3.519540e+11      4.539270e+11  ...   \n",
              "\n",
              "       CashProvidedByUsedInFinancingActivitiesDiscontinuedOperations  \\\n",
              "count                                       1.197820e+05               \n",
              "mean                                        4.410844e+04               \n",
              "std                                         4.800056e+07               \n",
              "min                                        -3.140119e+09               \n",
              "25%                                         0.000000e+00               \n",
              "50%                                         0.000000e+00               \n",
              "75%                                         0.000000e+00               \n",
              "max                                         1.199100e+10               \n",
              "\n",
              "       EffectOfExchangeRateFinal  \\\n",
              "count               1.197820e+05   \n",
              "mean               -3.048736e+06   \n",
              "std                 1.517667e+08   \n",
              "min                -3.234200e+10   \n",
              "25%                -1.000000e+03   \n",
              "50%                 0.000000e+00   \n",
              "75%                 0.000000e+00   \n",
              "max                 9.155000e+09   \n",
              "\n",
              "       CashPeriodIncreaseDecreaseIncludingExRateEffectFinal            GDP  \\\n",
              "count                                       1.197820e+05     119782.000000   \n",
              "mean                                        5.043658e+07          2.478345   \n",
              "std                                         2.748069e+09          8.919305   \n",
              "min                                        -1.736000e+11        -69.630993   \n",
              "25%                                        -1.385979e+07          1.388811   \n",
              "50%                                        -4.014000e+03          2.590671   \n",
              "75%                                         1.581288e+07          4.056326   \n",
              "max                                         2.639780e+11         45.706033   \n",
              "\n",
              "       interest_rate  unemployment_rate     median_cpi    market_cap  \\\n",
              "count  119782.000000      119782.000000  119782.000000  1.197820e+05   \n",
              "mean        0.978266           5.467949       2.777707  7.455004e+03   \n",
              "std         1.354245           1.837626       1.329234  4.203100e+04   \n",
              "min         0.050000           3.400000      -0.286064  5.317758e-06   \n",
              "25%         0.090000           3.900000       1.961900  8.357113e+01   \n",
              "50%         0.240000           5.000000       2.452308  6.248520e+02   \n",
              "75%         1.510000           6.700000       2.966116  3.175987e+03   \n",
              "max         5.330000          14.700000       8.048036  2.974308e+06   \n",
              "\n",
              "           small_cap      micro_cap  \n",
              "count  119782.000000  119782.000000  \n",
              "mean        0.679752       0.398992  \n",
              "std         0.466574       0.489693  \n",
              "min         0.000000       0.000000  \n",
              "25%         0.000000       0.000000  \n",
              "50%         1.000000       0.000000  \n",
              "75%         1.000000       1.000000  \n",
              "max         1.000000       1.000000  \n",
              "\n",
              "[8 rows x 45 columns]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(X_train_qtr).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "TBpPlofv0SO6"
      },
      "outputs": [],
      "source": [
        "# Step 7 : then the test data\n",
        "X_test_qtr_processed = preprocess_new_data(X_test_qtr, preprocessor_qtr)\n",
        "X_test_yr_processed = preprocess_new_data(X_test_yr, preprocessor_yr)\n",
        "X_test_2yr_processed = preprocess_new_data(X_test_2yr, preprocessor_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training logistic_regression: 100%|██████████ [elapsed: 00:04 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of iterations: [352]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy): 100%|██████████ [elapsed: 00:19 left: 00:00]\n",
            "Cross-Validation (precision): 100%|██████████ [elapsed: 00:19 left: 00:00]\n",
            "Cross-Validation (recall): 100%|██████████ [elapsed: 00:19 left: 00:00]\n",
            "Cross-Validation (f1): 100%|██████████ [elapsed: 00:19 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.6632, precision: 0.3379, recall: 0.5131, f1: 0.4002\n",
            "Model saved to: ~/models/logistic_regression_2024-09-11_16-02-30.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 8 :Train for quarterly (frequency=1), yearly (frequency=4), and 2-year (frequency=8) predictions\n",
        "y_pred_qtr_log_reg, model_qtr_log_reg = train_logistic_regression_and_save(X_train_qtr_processed, y_train_qtr, X_test_qtr_processed, y_test_qtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training logistic_regression: 100%|██████████ [elapsed: 00:01 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of iterations: [140]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy): 100%|██████████ [elapsed: 00:07 left: 00:00]\n",
            "Cross-Validation (precision): 100%|██████████ [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (recall): 100%|██████████ [elapsed: 00:06 left: 00:00]\n",
            "Cross-Validation (f1): 100%|██████████ [elapsed: 00:06 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.6606, precision: 0.3430, recall: 0.5238, f1: 0.4065\n",
            "Model saved to: ~/models/logistic_regression_2024-09-11_11-59-14.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_yr_log_reg, model_yr_log_reg = train_logistic_regression_and_save(X_train_yr_processed, y_train_yr, X_test_yr_processed, y_test_yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOMfwVi_1GDf",
        "outputId": "c2be492d-a575-47fc-c9c9-0ee5e3352a01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training logistic_regression: 100%|██████████ [elapsed: 00:06 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of iterations: [532]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation (accuracy): 100%|██████████ [elapsed: 00:13 left: 00:00]\n",
            "Cross-Validation (precision): 100%|██████████ [elapsed: 00:13 left: 00:00]\n",
            "Cross-Validation (recall): 100%|██████████ [elapsed: 00:13 left: 00:00]\n",
            "Cross-Validation (f1): 100%|██████████ [elapsed: 00:13 left: 00:00]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.6596, precision: 0.3333, recall: 0.5061, f1: 0.3966\n",
            "Model saved to: ~/models/logistic_regression_2024-09-11_12-01-22.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_2yr_log_reg, model_2yr = train_logistic_regression_and_save(X_train_2yr_processed, y_train_2yr, X_test_2yr_processed, y_test_2yr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training knn: 100%|██████████ [elapsed: 00:00 left: 00:00]\n",
            "Cross-Validation (accuracy): 100%|██████████ [elapsed: 00:12 left: 00:00]\n",
            "Cross-Validation (precision): 100%|██████████ [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (recall): 100%|██████████ [elapsed: 00:12 left: 00:00]\n",
            "Cross-Validation (f1): 100%|██████████ [elapsed: 00:12 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7477, precision: 0.4056, recall: 0.2794, f1: 0.3283\n",
            "Model saved to: ~/models/knn_2024-09-11_15-50-38.pkl\n"
          ]
        }
      ],
      "source": [
        "y_pred_qtr_knn, model_qtr_knn = train_knn_and_save(X_train_qtr_processed, y_train_qtr, X_test_qtr_processed, y_test_qtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training knn: 100%|██████████ [elapsed: 00:00 left: 00:00]\n",
            "Cross-Validation (accuracy): 100%|██████████ [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (precision): 100%|██████████ [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (recall): 100%|██████████ [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (f1): 100%|██████████ [elapsed: 00:12 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7298, precision: 0.3303, recall: 0.2014, f1: 0.2469\n",
            "Model saved to: ~/models/knn_2024-09-11_12-31-40.pkl\n"
          ]
        }
      ],
      "source": [
        "y_pred_yr_knn, model_yr_knn = train_knn_and_save(X_train_yr_processed, y_train_yr, X_test_yr_processed, y_test_yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training knn: 100%|██████████ [elapsed: 00:00 left: 00:00]\n",
            "Cross-Validation (accuracy): 100%|██████████ [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (precision): 100%|██████████ [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (recall): 100%|██████████ [elapsed: 00:11 left: 00:00]\n",
            "Cross-Validation (f1): 100%|██████████ [elapsed: 00:11 left: 00:00]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validated Metrics: accuracy: 0.7289, precision: 0.3252, recall: 0.1941, f1: 0.2402\n",
            "Model saved to: ~/models/knn_2024-09-11_12-35-40.pkl\n"
          ]
        }
      ],
      "source": [
        "y_pred_2yr_knn, model_2yr_knn = train_knn_and_save(X_train_2yr_processed, y_train_2yr, X_test_2yr_processed, y_test_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation: 100%|██████████ [elapsed: 00:04 left: 00:00]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Evaluates the model with cross-validation and test set metrics.\"\"\"\n",
        "with tqdm(total=5, desc=f\"Cross-Validation\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "    cv_metrics = cross_validate(SVC(kernel = 'rbf', class_weight='balanced'), X_train_qtr_processed[:10000], y_train_qtr[:10000], cv=3, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
        "    pbar.update(5)\n",
        "\n",
        "    #print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics.mean():.4f}' for m in cv_metrics])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'fit_time': array([0.71196508, 0.65307307, 0.65739298]),\n",
              " 'score_time': array([1.00231981, 0.83814096, 0.80731201]),\n",
              " 'test_accuracy': array([0.69406119, 0.64506451, 0.67566757]),\n",
              " 'test_precision': array([0.27086495, 0.25572519, 0.26061915]),\n",
              " 'test_recall': array([0.85817308, 0.9686747 , 0.87019231]),\n",
              " 'test_f1': array([0.41176471, 0.4046301 , 0.40110803])}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "      <td>120252.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.014093</td>\n",
              "      <td>0.013393</td>\n",
              "      <td>0.001951</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>0.012734</td>\n",
              "      <td>0.012177</td>\n",
              "      <td>0.014410</td>\n",
              "      <td>0.055566</td>\n",
              "      <td>0.055539</td>\n",
              "      <td>0.230144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000607</td>\n",
              "      <td>0.016781</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000582</td>\n",
              "      <td>0.000374</td>\n",
              "      <td>0.068423</td>\n",
              "      <td>0.250050</td>\n",
              "      <td>0.250823</td>\n",
              "      <td>0.250973</td>\n",
              "      <td>0.248154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.029071</td>\n",
              "      <td>0.028856</td>\n",
              "      <td>0.013157</td>\n",
              "      <td>0.042425</td>\n",
              "      <td>0.027675</td>\n",
              "      <td>0.026344</td>\n",
              "      <td>0.024527</td>\n",
              "      <td>0.033659</td>\n",
              "      <td>0.033611</td>\n",
              "      <td>0.018101</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024631</td>\n",
              "      <td>0.128452</td>\n",
              "      <td>0.010789</td>\n",
              "      <td>0.024120</td>\n",
              "      <td>0.019341</td>\n",
              "      <td>0.252471</td>\n",
              "      <td>0.433043</td>\n",
              "      <td>0.433489</td>\n",
              "      <td>0.433575</td>\n",
              "      <td>0.431943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.010949</td>\n",
              "      <td>0.010939</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.001541</td>\n",
              "      <td>0.010108</td>\n",
              "      <td>0.010104</td>\n",
              "      <td>0.009839</td>\n",
              "      <td>0.048932</td>\n",
              "      <td>0.048931</td>\n",
              "      <td>0.227502</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.011115</td>\n",
              "      <td>0.011015</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>0.001724</td>\n",
              "      <td>0.010202</td>\n",
              "      <td>0.010141</td>\n",
              "      <td>0.009910</td>\n",
              "      <td>0.049525</td>\n",
              "      <td>0.049520</td>\n",
              "      <td>0.227695</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.011814</td>\n",
              "      <td>0.011338</td>\n",
              "      <td>0.000879</td>\n",
              "      <td>0.004523</td>\n",
              "      <td>0.010685</td>\n",
              "      <td>0.010364</td>\n",
              "      <td>0.011182</td>\n",
              "      <td>0.052031</td>\n",
              "      <td>0.052007</td>\n",
              "      <td>0.228461</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 121 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0              1              2              3    \\\n",
              "count  120252.000000  120252.000000  120252.000000  120252.000000   \n",
              "mean        0.014093       0.013393       0.001951       0.011064   \n",
              "std         0.029071       0.028856       0.013157       0.042425   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.010949       0.010939       0.000121       0.001541   \n",
              "50%         0.011115       0.011015       0.000281       0.001724   \n",
              "75%         0.011814       0.011338       0.000879       0.004523   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 4              5              6              7    \\\n",
              "count  120252.000000  120252.000000  120252.000000  120252.000000   \n",
              "mean        0.012734       0.012177       0.014410       0.055566   \n",
              "std         0.027675       0.026344       0.024527       0.033659   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.010108       0.010104       0.009839       0.048932   \n",
              "50%         0.010202       0.010141       0.009910       0.049525   \n",
              "75%         0.010685       0.010364       0.011182       0.052031   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 8              9    ...            111            112  \\\n",
              "count  120252.000000  120252.000000  ...  120252.000000  120252.000000   \n",
              "mean        0.055539       0.230144  ...       0.000607       0.016781   \n",
              "std         0.033611       0.018101  ...       0.024631       0.128452   \n",
              "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
              "25%         0.048931       0.227502  ...       0.000000       0.000000   \n",
              "50%         0.049520       0.227695  ...       0.000000       0.000000   \n",
              "75%         0.052007       0.228461  ...       0.000000       0.000000   \n",
              "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
              "\n",
              "                 113            114            115            116  \\\n",
              "count  120252.000000  120252.000000  120252.000000  120252.000000   \n",
              "mean        0.000116       0.000582       0.000374       0.068423   \n",
              "std         0.010789       0.024120       0.019341       0.252471   \n",
              "min         0.000000       0.000000       0.000000       0.000000   \n",
              "25%         0.000000       0.000000       0.000000       0.000000   \n",
              "50%         0.000000       0.000000       0.000000       0.000000   \n",
              "75%         0.000000       0.000000       0.000000       0.000000   \n",
              "max         1.000000       1.000000       1.000000       1.000000   \n",
              "\n",
              "                 117            118            119            120  \n",
              "count  120252.000000  120252.000000  120252.000000  120252.000000  \n",
              "mean        0.250050       0.250823       0.250973       0.248154  \n",
              "std         0.433043       0.433489       0.433575       0.431943  \n",
              "min         0.000000       0.000000       0.000000       0.000000  \n",
              "25%         0.000000       0.000000       0.000000       0.000000  \n",
              "50%         0.000000       0.000000       0.000000       0.000000  \n",
              "75%         1.000000       1.000000       1.000000       0.000000  \n",
              "max         1.000000       1.000000       1.000000       1.000000  \n",
              "\n",
              "[8 rows x 121 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(X_train_qtr_processed).describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cross-Validation:   0%|           [elapsed: 00:00 left: ?]/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "Cross-Validation: 100%|██████████ [elapsed: 42:40 left: 00:00]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Evaluates the model with cross-validation and test set metrics.\"\"\"\n",
        "with tqdm(total=5, desc=f\"Cross-Validation\", bar_format='{l_bar}{bar} [elapsed: {elapsed} left: {remaining}]') as pbar:\n",
        "    cv_metrics = cross_validate(SVC(kernel = 'rbf'), X_train_qtr_processed, y_train_qtr, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n",
        "    pbar.update(5)\n",
        "\n",
        "    #print(f\"Cross-validated Metrics: {', '.join([f'{m}: {cv_metrics.mean():.4f}' for m in cv_metrics])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training svc_rbf:   0%|           [elapsed: 00:00 left: ?]"
          ]
        }
      ],
      "source": [
        "y_pred_qtr_svc, model_qtr_svc = train_svc_rbf_and_save(X_train_qtr_processed, y_train_qtr, X_test_qtr_processed, y_test_qtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_yr_svc, model_yr_svc = train_svc_rbf_and_save(X_train_yr_processed, y_train_yr, X_test_yr_processed, y_test_yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_2yr_svc, model_2yr_svc = train_svc_rbf_and_save(X_train_2yr_processed, y_train_2yr, X_test_2yr_processed, y_test_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7IFuQncCFAOI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Quarter Ahead Metrics: {'cv_accuracy': np.float64(0.5861177525890302), 'cv_precision': np.float64(0.28886531098782686), 'cv_recall': np.float64(0.3746608634582686), 'cv_f1': np.float64(0.32563369780978374), 'accuracy': 0.5739110464671209, 'precision': np.float64(0.28430531732418524), 'recall': np.float64(0.3731007315700619), 'f1': np.float64(0.32270625456315405)}\n",
            "1 Year Ahead Metrics: {'cv_accuracy': np.float64(0.5847497987573081), 'cv_precision': np.float64(0.2876763455297774), 'cv_recall': np.float64(0.37019406810692057), 'cv_f1': np.float64(0.3235231859899204), 'accuracy': 0.6013502387617322, 'precision': np.float64(0.3058765674944677), 'recall': np.float64(0.3812442537542139), 'f1': np.float64(0.33942701227830835)}\n",
            "2 Years Ahead Metrics: {'cv_accuracy': np.float64(0.5855911208007135), 'cv_precision': np.float64(0.2907180862789915), 'cv_recall': np.float64(0.378417465607723), 'cv_f1': np.float64(0.32827805522691694), 'accuracy': 0.6088211708099439, 'precision': np.float64(0.30460509390275275), 'recall': np.float64(0.3524858588865734), 'f1': np.float64(0.32680099365166987)}\n"
          ]
        }
      ],
      "source": [
        "# Step 10: Print metrics for each model\n",
        "print(\"1 Quarter Ahead Metrics:\", y_pred_qtr)\n",
        "print(\"1 Year Ahead Metrics:\", y_pred_yr)\n",
        "print(\"2 Years Ahead Metrics:\", y_pred_2yr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/eoingaynard/.pyenv/versions/3.10.6/envs/Small-Cap-Scout/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Let's try a grid search - QUARTER\n",
        "best_model_qtr, best_params_qtr, best_score_qtr = run_grid_search(X_train_qtr_processed, y_train_qtr)\n",
        "\n",
        "print(f\"Best Model - QUARTER: {best_model_qtr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - QUARTER: {best_params_qtr}\")\n",
        "print(f\"Best Score - QUARTER: {best_score_qtr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "Best parameters: {'C': 0.15, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
            "Best cross-validation score: 0.3543\n",
            "Best Model - YEAR: LogisticRegression\n",
            "Best Parameters - YEAR: {'C': 0.15, 'max_iter': 1500, 'solver': 'lbfgs'}\n",
            "Best Score - YEAR: 0.3543\n"
          ]
        }
      ],
      "source": [
        "# Let's try a grid search - YEAR\n",
        "best_model_yr, best_params_yr, best_score_yr = run_grid_search(X_train_yr_processed, y_train_yr)\n",
        "\n",
        "print(f\"Best Model - YEAR: {best_model_yr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - YEAR: {best_params_yr}\")\n",
        "print(f\"Best Score - YEAR: {best_score_yr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's try a grid search - 2 YEAR\n",
        "best_model_2yr, best_params_2yr, best_score_2yr = run_grid_search(X_train_2yr_processed, y_train_2yr)\n",
        "\n",
        "print(f\"Best Model - YEAR: {best_model_2yr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - YEAR: {best_params_2yr}\")\n",
        "print(f\"Best Score - YEAR: {best_score_2yr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "Best parameters: {'n_neighbors': 550}\n",
            "Best cross-validation score: 0.5641\n",
            "Best Model - QUARTER: KNeighborsClassifier\n",
            "Best Parameters - QUARTER: {'n_neighbors': 550}\n",
            "Best Score - QUARTER: 0.5641\n"
          ]
        }
      ],
      "source": [
        "# knn grid search\n",
        "# Let's try a grid search - QUARTER\n",
        "best_model_qtr, best_params_qtr, best_score_qtr = knn_run_grid_search(X_train_qtr_processed, y_train_qtr)\n",
        "\n",
        "print(f\"Best Model - QUARTER: {best_model_qtr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - QUARTER: {best_params_qtr}\")\n",
        "print(f\"Best Score - QUARTER: {best_score_qtr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Best parameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
            "Best cross-validation score: 0.6730\n",
            "Best Model - QUARTER: XGBClassifier\n",
            "Best Parameters - QUARTER: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200}\n",
            "Best Score - QUARTER: 0.6730\n"
          ]
        }
      ],
      "source": [
        "# xgboost  search\n",
        "# QUARTER\n",
        "best_model_qtr, best_params_qtr, best_score_qtr = run_xgboost(X_train_qtr_processed, y_train_qtr)\n",
        "\n",
        "print(f\"Best Model - QUARTER: {best_model_qtr.__class__.__name__}\")\n",
        "print(f\"Best Parameters - QUARTER: {best_params_qtr}\")\n",
        "print(f\"Best Score - QUARTER: {best_score_qtr:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      1.00      0.87     23202\n",
            "           1       0.70      0.03      0.06      6764\n",
            "\n",
            "    accuracy                           0.78     29966\n",
            "   macro avg       0.74      0.51      0.47     29966\n",
            "weighted avg       0.76      0.78      0.69     29966\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_model = XGBClassifier(learning_rate= 0.01, max_depth= 5, n_estimators= 200)\n",
        "best_model.fit(X_train_qtr_processed, y_train_qtr)\n",
        "predictions = best_model.predict(X_test_qtr_processed)\n",
        "\n",
        "report = classification_report(y_test_qtr, predictions)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test_qtr, predictions, labels=best_model.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=best_model.classes_)\n",
        "\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
