{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1800 [00:01<10:06,  2.96it/s]$ACET.Q: possibly delisted; no timezone found\n",
      "  0%|          | 8/1800 [00:03<09:00,  3.32it/s]$BYI: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      "  1%|          | 17/1800 [00:05<06:17,  4.73it/s]$IDSA: possibly delisted; no timezone found\n",
      "  2%|▏         | 35/1800 [00:09<06:02,  4.87it/s]$SSI: possibly delisted; no timezone found\n",
      "  2%|▏         | 38/1800 [00:10<08:40,  3.38it/s]$TREC: possibly delisted; no timezone found\n",
      "  3%|▎         | 52/1800 [00:14<06:30,  4.48it/s]$AVP: possibly delisted; no timezone found\n",
      "  3%|▎         | 56/1800 [00:15<07:48,  3.72it/s]$PTVC.B: possibly delisted; no timezone found\n",
      "  3%|▎         | 58/1800 [00:16<10:45,  2.70it/s]$BCR: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      "  3%|▎         | 61/1800 [00:17<07:36,  3.81it/s]$ESTE: possibly delisted; no timezone found\n",
      "  4%|▍         | 73/1800 [00:20<07:05,  4.06it/s]$BWL A: possibly delisted; no timezone found\n",
      "  4%|▍         | 75/1800 [00:21<10:46,  2.67it/s]$BGGS.Q: possibly delisted; no timezone found\n",
      "  4%|▍         | 77/1800 [00:22<11:47,  2.43it/s]$BF.B: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      "  5%|▍         | 85/1800 [00:24<05:31,  5.17it/s]$LUB: possibly delisted; no timezone found\n",
      "  5%|▍         | 89/1800 [00:25<08:00,  3.56it/s]$LBMH: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      "  5%|▌         | 91/1800 [00:26<06:10,  4.61it/s]$CTAM: possibly delisted; no timezone found\n",
      "  5%|▌         | 94/1800 [00:27<08:16,  3.44it/s]$CDI: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      "  5%|▌         | 98/1800 [00:28<06:00,  4.72it/s]$MGLN: possibly delisted; no timezone found\n",
      "  6%|▌         | 99/1800 [00:28<10:12,  2.78it/s]$CMD: possibly delisted; no timezone found\n",
      "  6%|▌         | 101/1800 [00:29<11:33,  2.45it/s]$TCF: possibly delisted; no timezone found\n",
      "  6%|▌         | 109/1800 [00:32<06:48,  4.14it/s]$CSS: possibly delisted; no timezone found\n",
      "  7%|▋         | 118/1800 [00:34<06:48,  4.12it/s]$CMRO: possibly delisted; no timezone found\n",
      "  7%|▋         | 122/1800 [00:36<07:55,  3.53it/s]$CTG: possibly delisted; no timezone found\n",
      "  7%|▋         | 126/1800 [00:37<08:03,  3.46it/s]$CNW: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      "  7%|▋         | 129/1800 [00:38<05:59,  4.65it/s]$CUO: possibly delisted; no timezone found\n",
      "  7%|▋         | 130/1800 [00:38<09:47,  2.84it/s]$CTB: possibly delisted; no timezone found\n",
      "  7%|▋         | 133/1800 [00:40<11:24,  2.43it/s]$CRRC: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      "  8%|▊         | 135/1800 [00:40<08:27,  3.28it/s]$CRD.B: possibly delisted; no timezone found\n",
      "  8%|▊         | 153/1800 [00:45<05:46,  4.75it/s]$RRD: possibly delisted; no timezone found\n",
      "  9%|▊         | 154/1800 [00:45<10:18,  2.66it/s]$ESCR.Q: possibly delisted; no timezone found\n",
      "  9%|▉         | 168/1800 [00:49<05:34,  4.88it/s]$ELRC: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      "  9%|▉         | 170/1800 [00:49<04:04,  6.66it/s]$MTWD: possibly delisted; no timezone found\n",
      " 10%|▉         | 173/1800 [00:51<08:28,  3.20it/s]$EDE: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      " 10%|▉         | 179/1800 [00:52<06:18,  4.29it/s]$ESL: possibly delisted; no timezone found\n",
      " 10%|█         | 180/1800 [00:53<12:19,  2.19it/s]$BOBE: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      " 10%|█         | 185/1800 [00:54<07:40,  3.51it/s]$FDO: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      " 10%|█         | 188/1800 [00:54<05:20,  5.03it/s]$FOE: possibly delisted; no timezone found\n",
      " 11%|█         | 191/1800 [00:56<08:07,  3.30it/s]$CLGX: possibly delisted; no timezone found\n",
      " 11%|█         | 197/1800 [00:58<06:51,  3.89it/s]$MFNC: possibly delisted; no timezone found\n",
      " 11%|█         | 199/1800 [00:59<09:48,  2.72it/s]$FWV: possibly delisted; no price data found  (1d 2010-01-01 -> 2024-09-05)\n",
      " 11%|█▏        | 204/1800 [01:00<06:22,  4.17it/s]"
     ]
    }
   ],
   "source": [
    "def fetch_stock_data(ticker):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        data = stock.history(start=\"2010-01-01\", end=datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "        data = data.reset_index()\n",
    "        data['Ticker'] = ticker\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_batch(tickers, batch_size=1800, time_limit=3600):\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, ticker in enumerate(tqdm(tickers)):\n",
    "        results.append(fetch_stock_data(ticker))\n",
    "\n",
    "        if (i + 1) % batch_size == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            if elapsed_time < time_limit:\n",
    "                time.sleep(time_limit - elapsed_time)\n",
    "            start_time = time.time()\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "def main():\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv('~/Small-Cap-Scout/raw_data/cik_ticker_pairs.csv')\n",
    "\n",
    "    # Get the list of tickers\n",
    "    tickers = df['TICKER'].tolist()\n",
    "\n",
    "    all_data = pd.DataFrame()\n",
    "    batch_size = 1800  # Slightly under 2000 to account for potential errors\n",
    "\n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i+batch_size]\n",
    "        print(f\"Processing batch {i//batch_size + 1} of {len(tickers)//batch_size + 1}\")\n",
    "        batch_data = process_batch(batch)\n",
    "        all_data = pd.concat([all_data, batch_data], ignore_index=True)\n",
    "\n",
    "        # Save intermediate results\n",
    "        all_data.to_csv(f'yahoo_stock_data_since_2010_batch_{i//batch_size + 1}.csv', index=False)\n",
    "\n",
    "    # Save final results\n",
    "    all_data.to_csv('yahoo_stock_data_since_2010_complete.csv', index=False)\n",
    "\n",
    "    print(\"Data collection complete. Final results saved to yahoo_stock_data_since_2010_complete.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Small-Cap-Scout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
